# –î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´ –ù–ï–ô–†–û–î–ï–¢–ï–ö–¢

## üîß –¢–ï–•–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –°–¢–ï–ö

### –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
- **Python 3.8+** - –æ—Å–Ω–æ–≤–Ω–æ–π —è–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
- **PyTorch 1.12.1** - —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
- **CUDA 11.6** - —É—Å–∫–æ—Ä–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –Ω–∞ GPU
- **NumPy 1.24.3** - —á–∏—Å–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—Å—Å–∏–≤—ã
- **Pandas 1.5.3** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **Scikit-learn 1.2.2** - –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –º–µ—Ç—Ä–∏–∫–∏
- **Matplotlib 3.7.1** - –±–∞–∑–æ–≤–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **Seaborn 0.12.2** - —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **PyYAML 6.0** - –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
- **Pickle** - —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ Python

---

## üìä –≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê –ò –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–•

### 1.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö

```python
# –ò–µ—Ä–∞—Ä—Ö–∏—è –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
src/utils/data_processing.py
‚îú‚îÄ‚îÄ load_files()           # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ PLAID
‚îú‚îÄ‚îÄ Encoder –∫–ª–∞—Å—Å          # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤  
‚îú‚îÄ‚îÄ SequenceDataset()      # PyTorch Dataset –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
‚îú‚îÄ‚îÄ SequencePairDataset()  # Dataset –¥–ª—è –ø–∞—Ä –≤—Ö–æ–¥-–≤—ã—Ö–æ–¥
‚îú‚îÄ‚îÄ load_data_splits()     # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö 60/20/20
‚îî‚îÄ‚îÄ get_data()             # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤
```

### 1.2 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö

**–ê–ª–≥–æ—Ä–∏—Ç–º –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤:**
```python
def load_files(data_set, nested=False):
    # 1. –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
    attack_files = sorted(list(Path("data/PLAID/attack").rglob("*.txt")))
    baseline_files = list(Path("data/PLAID/baseline").rglob("*.txt"))
    
    # 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π (8-4495)
    if 4495 >= len(seq) >= 8:
        ret.append(seq)
    
    # 3. –í–æ–∑–≤—Ä–∞—Ç —Å—ã—Ä—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤
```

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**
- –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∞—Ç–∞–∫: 1,145
- –ù–∞–π–¥–µ–Ω–æ –±–∞–∑–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: 38,178  
- –û–±—â–∏–π –æ–±—ä–µ–º: 39,323 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª–∏–Ω–æ–π 8-4,495 –≤—ã–∑–æ–≤–æ–≤

### 1.3 –°–∏—Å—Ç–µ–º–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π

**–ö–ª–∞—Å—Å Encoder - —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:**
```python
class Encoder:
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è: —Å—Ç—Ä–æ–∫–∞ -> —á–∏—Å–ª–æ
    # –ö–∞–∂–¥—ã–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –≤—ã–∑–æ–≤ –ø–æ–ª—É—á–∞–µ—Ç ID
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: PAD=0, UNK –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö
    
    def encode(self, syscall_name):
        return self.vocab.get(syscall_name, self.unk_id)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø–æ–¥—Ö–æ–¥–∞:**
- –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤  
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ (int32 vs string)
- –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å PyTorch tensors

### 1.4 –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è 60/20/20:**
```python
train_split = 0.6   # 60% –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
val_split = 0.2     # 20% –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏  
test_split = 0.2    # 20% –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö + –í–°–ï –∞—Ç–∞–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ: —Ä–∞–Ω–¥–æ–º–Ω–æ–µ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏–µ
normal_idxs = np.arange(len(normal_files))
np.random.shuffle(normal_idxs)
```

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**
- –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –æ–±—É—á–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
- –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å–µ —Ç–∏–ø—ã –∞—Ç–∞–∫
- –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏

### 1.5 PyTorch DataLoader –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –±–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π:**
```python
def collate_fn(batch):
    # –ü—Ä–æ–±–ª–µ–º–∞: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã
    # –†–µ—à–µ–Ω–∏–µ: Dynamic padding –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ
    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)
    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)
```

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**
- `num_workers=0` - –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ multiprocessing (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)
- `pin_memory=False` - —ç–∫–æ–Ω–æ–º–∏—è GPU –ø–∞–º—è—Ç–∏
- `batch_first=True` - —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å PyTorch LSTM
- Dynamic batching - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏

### 1.6 –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å

**–î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:**
```python
# –£—Ä–æ–≤–µ–Ω—å 1: Pickle (–±—ã—Å—Ç—Ä–æ, Python-specific)
pickle_path = Path(f"out/{data_set}_split60_20_20.pkl")
save_pickle([train, val, test_val, atk], pickle_path)

# –£—Ä–æ–≤–µ–Ω—å 2: NumPy (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å, –∫–æ–º–ø–∞–∫—Ç–Ω–æ)  
np.savez(out_path, data_to_save)
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**
- –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
- –≠–∫–æ–Ω–æ–º–∏—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—É—Å–∫–∞—Ö
- –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö

---

## üß† –≠–¢–ê–ü 2: –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –ù–ï–ô–†–û–°–ï–¢–ï–í–´–• –ú–û–î–ï–õ–ï–ô

### 2.1 GRU-–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä: —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è —Å—Ö–µ–º–∞:**
```
Input ‚Üí Embedding(151‚Üí64) ‚Üí GRU(64‚Üí128, 2layers) ‚Üí Hidden State
Hidden State ‚Üí GRU(128‚Üí64, 2layers) ‚Üí Linear(128‚Üí151) ‚Üí Output
```

**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
```python
class GRUAutoEncoder(nn.Module):
    vocab_size = 151        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –≤—ã–∑–æ–≤—ã
    embedding_dim = 64      # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    hidden_dim = 128        # –°–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è GRU
    num_layers = 2          # –ì–ª—É–±–∏–Ω–∞ —Å–µ—Ç–∏
    dropout = 0.2           # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
```

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π:**
```python
def get_reconstruction_error(self, x):
    # 1. –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —ç–Ω–∫–æ–¥–µ—Ä
    encoded = self.encode(x)
    
    # 2. –î–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ –∏—Å—Ö–æ–¥–Ω—É—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    decoded = self.decode(encoded, x.size(1))
    
    # 3. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ MSE –º–µ–∂–¥—É –≤—Ö–æ–¥–æ–º –∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π
    error = F.mse_loss(decoded, x.float(), reduction='none')
    
    # 4. –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    return error.mean(dim=1)
```

### 2.2 LSTM –º–æ–¥–µ–ª—å: –∞–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π

**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:**
```python
class LSTMModel(nn.Module):
    embedding = nn.Embedding(151, 384)      # –ë–æ–ª—å—à–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    lstm = nn.LSTM(384, 384, 3, dropout=0.15)  # 3 —Å–ª–æ—è, 384 –Ω–µ–π—Ä–æ–Ω–∞
    classifier = nn.Linear(384, 151)        # Softmax –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
```

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π:**
```python
# –ü–µ—Ä–ø–ª–µ–∫—Å–∏—è –∫–∞–∫ –º–µ—Ä–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏
def get_perplexity_score(outputs, targets):
    loss = F.cross_entropy(outputs.view(-1, vocab_size), 
                          targets.view(-1), reduction='mean')
    perplexity = torch.exp(loss)
    return perplexity.item()

# –í—ã—Å–æ–∫–∞—è –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è = –∞–Ω–æ–º–∞–ª–∏—è
```

**–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–∞:**
- –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –≤—ã–∑–æ–≤
- –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ—é—Ç –Ω–∏–∑–∫—É—é –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é  
- –ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç—Ä—É–¥–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å ‚Üí –≤—ã—Å–æ–∫–∞—è –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è

---

## ‚öôÔ∏è –≠–¢–ê–ü 3: –¢–ï–•–ù–û–õ–û–ì–ò–ò –û–ë–£–ß–ï–ù–ò–Ø –ò –í–ê–õ–ò–î–ê–¶–ò–ò

### 3.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ pipeline

**–ú–æ–¥—É–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–Ω–µ—Ä–æ–≤:**
```python
src/training/
‚îú‚îÄ‚îÄ trainer.py              # –ë–∞–∑–æ–≤—ã–π –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å
‚îú‚îÄ‚îÄ lstm_trainer.py         # LSTM-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
‚îî‚îÄ‚îÄ autoencoder_trainer.py  # –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
```

### 3.2 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ —Ä–∞–Ω–Ω–µ–≥–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è

**–ê–ª–≥–æ—Ä–∏—Ç–º EarlyStopping:**
```python
class EarlyStopping:
    def __init__(self, patience=8, min_delta=1e-4, mode='min'):
        self.patience = patience        # –¢–µ—Ä–ø–µ–Ω–∏–µ: 8 —ç–ø–æ—Ö –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è
        self.min_delta = min_delta     # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–∏–º–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
        self.best_score = None
        self.counter = 0
        
    def __call__(self, val_loss):
        if self.best_score is None:
            self.best_score = val_loss
        elif val_loss < self.best_score - self.min_delta:
            self.best_score = val_loss
            self.counter = 0  # –°–±—Ä–æ—Å —Å—á–µ—Ç—á–∏–∫–∞
        else:
            self.counter += 1
            
        return self.counter >= self.patience
```

### 3.3 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –æ–±—É—á–µ–Ω–∏—è

**–°–∏—Å—Ç–µ–º–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫:**
```python
class LossTracker:
    def __init__(self):
        self.train_losses = []
        self.val_losses = []
        self.train_accuracies = []
        self.val_accuracies = []
        
    def update(self, train_loss, val_loss, train_acc, val_acc):
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ pickle –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
```

### 3.4 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

**Adam –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å —Ä–∞–∑–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:**
```python
# GRU-–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä (–±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ)
optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)

# LSTM (–º–µ–¥–ª–µ–Ω–Ω–æ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ)  
optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)
```

**Gradient Clipping:**
```python
# –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –≤–∑—Ä—ã–≤–∞—é—â–∏—Ö—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

**Dropout —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏:**
- GRU-AE: 0.2 (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)
- LSTM: 0.15 (–±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è)

### 3.5 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è checkpoint'–æ–≤:**
```python
def save_checkpoint(self, epoch, model, optimizer, loss, path):
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
        'config': self.config,
        'timestamp': datetime.now().isoformat()
    }
    torch.save(checkpoint, path)
```

---

## üìà –≠–¢–ê–ü 4: –¢–ï–•–ù–û–õ–û–ì–ò–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ò –í–ê–õ–ò–î–ê–¶–ò–ò

### 4.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã –æ—Ü–µ–Ω–∫–∏

**–ú–æ–¥—É–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ evaluator'–æ–≤:**
```python
src/testing/evaluator.py
‚îú‚îÄ‚îÄ Evaluator              # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å  
‚îú‚îÄ‚îÄ LSTMEvaluator         # LSTM-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
‚îî‚îÄ‚îÄ AutoencoderEvaluator  # –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
```

### 4.2 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫

**–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–µ—Ç—Ä–∏–∫:**
```python
def calculate_metrics(y_true, y_pred, y_scores=None):
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred, zero_division=0),
        'recall': recall_score(y_true, y_pred, zero_division=0),
        'f1_score': f1_score(y_true, y_pred, zero_division=0),
        'specificity': specificity_score(y_true, y_pred),
        'npv': npv_score(y_true, y_pred)
    }
    
    if y_scores is not None:
        metrics['roc_auc'] = roc_auc_score(y_true, y_scores)
        metrics['average_precision'] = average_precision_score(y_true, y_scores)
        
    return metrics
```

### 4.3 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞

**–ê–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞:**
```python
from sklearn.metrics import roc_curve

def find_optimal_threshold(y_true, y_scores):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    
    # –ú–µ—Ç–æ–¥ –Æ–¥–µ–Ω–∞: –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è (TPR - FPR)
    youden_index = tpr - fpr
    optimal_idx = np.argmax(youden_index)
    optimal_threshold = thresholds[optimal_idx]
    
    return optimal_threshold
```

### 4.4 –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è

**Bootstrap –∞–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:**
```python
def bootstrap_metrics(y_true, y_pred, n_bootstrap=1000):
    bootstrap_scores = []
    n_samples = len(y_true)
    
    for i in range(n_bootstrap):
        # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ —Å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º
        indices = np.random.choice(n_samples, n_samples, replace=True)
        bootstrap_true = y_true[indices]
        bootstrap_pred = y_pred[indices]
        
        score = f1_score(bootstrap_true, bootstrap_pred)
        bootstrap_scores.append(score)
    
    # 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    ci_lower = np.percentile(bootstrap_scores, 2.5)
    ci_upper = np.percentile(bootstrap_scores, 97.5)
    
    return ci_lower, ci_upper
```

---

## üìä –≠–¢–ê–ü 5: –¢–ï–•–ù–û–õ–û–ì–ò–ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò –ò –ê–ù–ê–õ–ò–ó–ê

### 5.1 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥—É–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ plotting —Å–∏—Å—Ç–µ–º—ã:**
```python
src/visualization/
‚îú‚îÄ‚îÄ training_plotter.py     # –ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ results_plotter.py      # ROC, PR –∫—Ä–∏–≤—ã–µ  
‚îú‚îÄ‚îÄ comparison_plotter.py   # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚îî‚îÄ‚îÄ analysis_plotter.py     # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
```

### 5.2 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤

**ROC-AUC –∞–Ω–∞–ª–∏–∑ (autoencoder_vs_lstm_comparison_roc_curve.png):**
```python
def plot_roc_curve(y_true, y_scores, title="ROC Curve"):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    auc_score = auc(fpr, tpr)
    
    plt.figure(figsize=(10, 8))
    plt.plot(fpr, tpr, linewidth=3, 
             label=f'ROC curve (AUC = {auc_score:.4f})')
    plt.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.6)
    
    # –û—Ç–º–µ—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
    optimal_idx = np.argmax(tpr - fpr)
    plt.scatter(fpr[optimal_idx], tpr[optimal_idx], 
                color='red', s=100, zorder=5)
```

**Precision-Recall –∞–Ω–∞–ª–∏–∑ (autoencoder_vs_lstm_comparison_precision_recall.png):**
```python
def plot_precision_recall_curve(y_true, y_scores):
    precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
    avg_precision = average_precision_score(y_true, y_scores)
    
    plt.figure(figsize=(10, 8))
    plt.plot(recall, precision, linewidth=3,
             label=f'PR curve (AP = {avg_precision:.4f})')
    
    # Baseline (random classifier)
    baseline = np.sum(y_true) / len(y_true)
    plt.axhline(y=baseline, color='k', linestyle='--', alpha=0.6)
```

### 5.3 –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (comprehensive_analysis.png)

**4-–ø–∞–Ω–µ–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

# –ü–∞–Ω–µ–ª—å 1: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
ax1.hist(normal_errors, bins=50, alpha=0.7, label='Normal', density=True)
ax1.hist(attack_errors, bins=50, alpha=0.7, label='Attacks', density=True)
ax1.axvline(threshold, color='red', linestyle='--', label='Threshold')

# –ü–∞–Ω–µ–ª—å 2: ROC –∫—Ä–∏–≤–∞—è
plot_roc_on_axis(ax2, y_true, y_scores)

# –ü–∞–Ω–µ–ª—å 3: Precision-Recall –∫—Ä–∏–≤–∞—è  
plot_pr_on_axis(ax3, y_true, y_scores)

# –ü–∞–Ω–µ–ª—å 4: Confusion Matrix
plot_confusion_matrix_on_axis(ax4, y_true, y_pred)
```

### 5.4 –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è (training_history.png)

**–î–≤—É—Ö–ø–∞–Ω–µ–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
def plot_training_history(history):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Loss curves
    ax1.plot(history['train_loss'], label='Training Loss', linewidth=2)
    ax1.plot(history['val_loss'], label='Validation Loss', linewidth=2)
    ax1.set_ylabel('Loss')
    ax1.set_xlabel('Epoch')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Accuracy curves (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
    if 'train_acc' in history:
        ax2.plot(history['train_acc'], label='Training Accuracy', linewidth=2)
        ax2.plot(history['val_acc'], label='Validation Accuracy', linewidth=2)
        ax2.set_ylabel('Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
```

---

## üî¨ –≠–¢–ê–ü 6: –¢–ï–•–ù–û–õ–û–ì–ò–ò –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê

### 6.1 –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏

**–ö—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–∫–Ω–µ–º–∞—Ä–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤:**
```python
from statsmodels.stats.contingency_tables import mcnemar

def mcnemar_test(y_true, y_pred1, y_pred2):
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂–µ–Ω–Ω–æ—Å—Ç–∏
    correct_1 = (y_true == y_pred1)
    correct_2 = (y_true == y_pred2)
    
    # –°–ª—É—á–∞–∏ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è
    diff_12 = np.sum(correct_1 & ~correct_2)  # –ú–æ–¥–µ–ª—å 1 –ø—Ä–∞–≤–∞, 2 –Ω–µ—Ç
    diff_21 = np.sum(~correct_1 & correct_2)  # –ú–æ–¥–µ–ª—å 2 –ø—Ä–∞–≤–∞, 1 –Ω–µ—Ç
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ú–∞–∫–Ω–µ–º–∞—Ä–∞
    statistic = (abs(diff_12 - diff_21) - 1)**2 / (diff_12 + diff_21)
    p_value = 1 - chi2.cdf(statistic, 1)
    
    return statistic, p_value
```

### 6.2 –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –∞–Ω—Å–∞–º–±–ª–µ–≤—ã—Ö –º–µ—Ç–æ–¥–æ–≤

**–í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π:**
```python
class EnsembleModel:
    def predict_ensemble(self, test_loader, strategy="weighted_voting", weights=(0.6, 0.4)):
        # –ü–æ–ª—É—á–∞–µ–º —Å–∫–æ—Ä—ã –æ—Ç –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π
        lstm_scores = self.get_lstm_scores(test_loader)
        ae_scores = self.get_autoencoder_scores(test_loader)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤ [0,1]
        lstm_norm = (lstm_scores - lstm_scores.min()) / (lstm_scores.max() - lstm_scores.min())
        ae_norm = (ae_scores - ae_scores.min()) / (ae_scores.max() - ae_scores.min())
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
        w_lstm, w_ae = weights
        ensemble_scores = w_lstm * lstm_norm + w_ae * ae_norm
        
        return ensemble_scores
```

---

## üíæ –¢–ï–•–ù–û–õ–û–ì–ò–ò –ü–ï–†–°–ò–°–¢–ï–ù–¢–ù–û–°–¢–ò –ò –í–û–°–ü–†–û–ò–ó–í–û–î–ò–ú–û–°–¢–ò

### –°–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
```python
class NeuroDetekt:
    def _create_experiment_dir(self, experiment_name):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        experiment_dir = Path(self.config['paths']['base_dir']) / f"{experiment_name}_{timestamp}"
        experiment_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        config_path = experiment_dir / "config.yaml"
        with open(config_path, 'w') as f:
            yaml.dump(self.config, f, default_flow_style=False)
            
        return experiment_dir
```

### –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
```python
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
```

---

## üìä –ê–ù–ê–õ–ò–ó –ì–†–ê–§–ò–ö–û–í –ò–ó TRIALS

### –ì—Ä–∞—Ñ–∏–∫ 1: ROC-–∫—Ä–∏–≤–∞—è (autoencoder_vs_lstm_comparison_roc_curve.png)
**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:**
- **AUC = 0.9296** - –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
- **–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ –Æ–¥–µ–Ω–∞** - –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ—Ç (TPR - FPR)
- **–ö—Ä—É—Ç–æ–π –ø–æ–¥—ä–µ–º –≤ –Ω–∞—á–∞–ª–µ** - –≤—ã—Å–æ–∫–∞—è —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∏ –Ω–∏–∑–∫–æ–π FPR
- **–ü–ª–æ—â–∞–¥—å –ø–æ–¥ –∫—Ä–∏–≤–æ–π** —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ø–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω—É—é —Å–µ–ø–∞—Ä–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–æ–≤

### –ì—Ä–∞—Ñ–∏–∫ 2: Precision-Recall –∫—Ä–∏–≤–∞—è (autoencoder_vs_lstm_comparison_precision_recall.png)  
**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:**
- **Average Precision = 0.5291** - —É–º–µ—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–†–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ precision** –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–º recall - —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–≤
- **Baseline = 0.13** (–¥–æ–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤)
- **–û–±–ª–∞—Å—Ç—å –ø–æ–¥ –∫—Ä–∏–≤–æ–π** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–º–ø—Ä–æ–º–∏—Å—Å precision/recall

### –ì—Ä–∞—Ñ–∏–∫ 3: –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (comprehensive_analysis.png)
**4-–ø–∞–Ω–µ–ª—å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑:**

**–ü–∞–Ω–µ–ª—å 1 - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫:**
- –ß–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ (Œº=2.28) –∏ –∞—Ç–∞–∫–∞–º–∏ (Œº=3.97)
- –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –æ–±—ä—è—Å–Ω—è–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
- –ü–æ—Ä–æ–≥ 2.99 –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –∫–ª–∞—Å—Å—ã

**–ü–∞–Ω–µ–ª—å 2 - ROC –∞–Ω–∞–ª–∏–∑:**
- –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç AUC = 0.9296
- –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–±–æ—á–∞—è —Ç–æ—á–∫–∞ –æ—Ç–º–µ—á–µ–Ω–∞ –∫—Ä–∞—Å–Ω—ã–º

**–ü–∞–Ω–µ–ª—å 3 - PR –∞–Ω–∞–ª–∏–∑:**
- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–π–¥–æ—Ñ—Ñ precision vs recall
- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤

**–ü–∞–Ω–µ–ª—å 4 - Confusion Matrix:**
- TP=1131, FP=880, TN=6757, FN=14
- –ù–∞–≥–ª—è–¥–Ω–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –≤—ã—Å–æ–∫–∏–π recall, –Ω–æ —É–º–µ—Ä–µ–Ω–Ω—ã–π precision

### –ì—Ä–∞—Ñ–∏–∫ 4: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è (training_history.png)
**–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏–∏:**
- **–°—Ç–∞–±–∏–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è** –∑–∞ 15 —ç–ø–æ—Ö
- **–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** - –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –∫—Ä–∏–≤–∞—è —Å–ª–µ–¥—É–µ—Ç –∑–∞ –æ–±—É—á–∞—é—â–µ–π
- **–†–∞–Ω–Ω–µ–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ** —Å—Ä–∞–±–æ—Ç–∞–ª–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
- **–ì–ª–∞–¥–∫–∏–µ –∫—Ä–∏–≤—ã–µ** —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

### –ì—Ä–∞—Ñ–∏–∫ 5: –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (final_model_results.png)
**LSTM –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑:**
- –ë–æ–ª–µ–µ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è confusion matrix
- –ú–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
- –°—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–∞—Ö –¥–∞–Ω–Ω—ã—Ö

### –ì—Ä–∞—Ñ–∏–∫ 6: –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (final_model_training.png)
**–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è LSTM:**
- **22 —ç–ø–æ—Ö–∏** –¥–æ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ (vs 15 —É –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞)
- **–ë–æ–ª–µ–µ –º–µ–¥–ª–µ–Ω–Ω–∞—è –∫–æ–Ω–≤–µ—Ä–≥–µ–Ω—Ü–∏—è** –∏–∑-–∑–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- **–°—Ç–∞–±–∏–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ** –º–µ—Ç—Ä–∏–∫ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –æ–±—É—á–µ–Ω–∏—è

---

## üéØ –¢–ï–•–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ï –í–´–í–û–î–´

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
1. **–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å** - —á–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
2. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –ª–µ–≥–∫–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
3. **–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** - –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
4. **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å** - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ GPU
5. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
6. **–ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å** - –Ω–∞–¥–µ–∂–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏:
1. **–ê–¥–∞–ø—Ç–∞—Ü–∏—è LSTM** –¥–ª—è unsupervised –¥–µ—Ç–µ–∫—Ü–∏–∏ —á–µ—Ä–µ–∑ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é
2. **–î–≤—É—Ö—É—Ä–æ–≤–Ω–µ–≤–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ** –¥–∞–Ω–Ω—ã—Ö (pickle + numpy)
3. **Dynamic padding** –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª–∏–Ω—ã
4. **–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è** —Å 4-–ø–∞–Ω–µ–ª—å–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
5. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π** –≤—ã–±–æ—Ä –ø–æ—Ä–æ–≥–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏
6. **–ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã** –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π

–î–∞–Ω–Ω–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—É—é –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã –∏ —Å–ª—É–∂–∏—Ç –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Å–Ω–æ–≤–æ–π –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç—Ç–∞–ø–∞ - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å reinforcement learning. 