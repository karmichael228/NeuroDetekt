# ОТЧЕТ ПО НАУЧНО-ИССЛЕДОВАТЕЛЬСКОЙ РАБОТЕ

## ТЕМА: Разработка метода автоматической реакции на аномалии в кибербезопасности на основе нейросетей и обучения с подкреплением

---

## АННОТАЦИЯ

В рамках данного исследования была проведена работа по разработке системы автоматического обнаружения аномалий в кибербезопасности с использованием нейросетевых технологий. Исследование включало подготовку и анализ датасета PLAID, проектирование и сравнение архитектур нейросетевых моделей (GRU-автоэнкодер и LSTM), а также всестороннюю оценку их производительности. Получены значимые результаты, демонстрирующие эффективность предложенных подходов для детекции аномалий в системных вызовах.

**Ключевые слова:** кибербезопасность, нейронные сети, обнаружение аномалий, системные вызовы, автоэнкодеры, LSTM

---

## СОДЕРЖАНИЕ

1. [ВВЕДЕНИЕ](#1-введение)
2. [ОБЗОР ЛИТЕРАТУРЫ И ПОСТАНОВКА ЗАДАЧИ](#2-обзор-литературы-и-постановка-задачи)
3. [МЕТОДОЛОГИЯ ИССЛЕДОВАНИЯ](#3-методология-исследования)
4. [ПОДГОТОВКА И АНАЛИЗ ДАТАСЕТА](#4-подготовка-и-анализ-датасета)
5. [ПРОЕКТИРОВАНИЕ АРХИТЕКТУР МОДЕЛЕЙ](#5-проектирование-архитектур-моделей)
6. [ОБУЧЕНИЕ И ВАЛИДАЦИЯ МОДЕЛЕЙ](#6-обучение-и-валидация-моделей)
7. [ЭКСПЕРИМЕНТАЛЬНЫЕ РЕЗУЛЬТАТЫ](#7-экспериментальные-результаты)
8. [СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ](#8-сравнительный-анализ-моделей)
9. [ОБСУЖДЕНИЕ РЕЗУЛЬТАТОВ](#9-обсуждение-результатов)
10. [ЗАКЛЮЧЕНИЕ И НАПРАВЛЕНИЯ ДАЛЬНЕЙШИХ ИССЛЕДОВАНИЙ](#10-заключение-и-направления-дальнейших-исследований)
11. [СПИСОК ЛИТЕРАТУРЫ](#11-список-литературы)
12. [ПРИЛОЖЕНИЯ](#12-приложения)

---

## 1. ВВЕДЕНИЕ

### 1.1 Актуальность исследования

Проблема обнаружения кибератак и аномального поведения в информационных системах является одной из наиболее критических в современной области кибербезопасности. С ростом сложности и масштабов IT-инфраструктуры традиционные методы детекции становятся недостаточно эффективными. Необходимость в автоматизированных системах, способных в реальном времени обнаруживать неизвестные ранее типы атак и аномалий, становится все более острой.

### 1.2 Цели и задачи исследования

**Основная цель:** Разработка и исследование эффективного метода автоматического обнаружения аномалий в кибербезопасности на основе анализа системных вызовов с использованием нейросетевых технологий.

**Задачи исследования:**
1. Подбор и подготовка репрезентативного датасета для обучения моделей
2. Проектирование архитектур нейросетевых моделей для детекции аномалий
3. Обучение и валидация разработанных моделей
4. Комплексное тестирование и оценка производительности
5. Сравнительный анализ различных подходов
6. Документирование результатов и подготовка к следующему этапу исследования

### 1.3 Научная новизна

Научная новизна работы заключается в:
- Комплексном сравнении архитектур GRU-автоэнкодера и LSTM для задач детекции аномалий в системных вызовах
- Разработке специализированных метрик оценки для данной предметной области
- Создании методологии preprocessing и анализа данных системных вызовов

---

## 2. ОБЗОР ЛИТЕРАТУРЫ И ПОСТАНОВКА ЗАДАЧИ

### 2.1 Современные подходы к обнаружению аномалий

Современные методы обнаружения аномалий в кибербезопасности можно разделить на несколько категорий:

1. **Статистические методы** - основаны на анализе статистических характеристик данных
2. **Методы машинного обучения** - включают классические алгоритмы (SVM, Random Forest)
3. **Глубокое обучение** - нейросетевые подходы для выявления сложных паттернов

### 2.2 Анализ системных вызовов

Системные вызовы представляют собой интерфейс между пользовательскими программами и ядром операционной системы. Последовательности системных вызовов отражают поведение процессов и могут служить индикаторами аномальной активности.

### 2.3 Автоэнкодеры для детекции аномалий

Автоэнкодеры - это нейронные сети, обученные воспроизводить входные данные через узкое бутылочное горлышко. Для детекции аномалий они обучаются на нормальных данных, и высокая ошибка реконструкции указывает на аномалию.

### 2.4 Рекуррентные нейронные сети

LSTM и GRU сети эффективно обрабатывают последовательные данные, что делает их подходящими для анализа временных паттернов в системных вызовах.

---

## 3. МЕТОДОЛОГИЯ ИССЛЕДОВАНИЯ

### 3.1 Общий подход

Исследование проводилось в рамках экспериментальной методологии с использованием количественных методов оценки. Все эксперименты воспроизводимы и документированы.

### 3.2 Программная реализация

Система реализована на языке Python с использованием следующих основных библиотек:
- **PyTorch** - для создания и обучения нейросетевых моделей
- **NumPy/Pandas** - для обработки данных
- **Scikit-learn** - для метрик и валидации
- **Matplotlib/Seaborn** - для визуализации результатов

### 3.3 Аппаратное обеспечение

Эксперименты проводились на системе с GPU поддержкой (CUDA), что обеспечило эффективное обучение моделей.

### 3.4 Метрики оценки

Для оценки качества моделей использовались следующие метрики:
- **Accuracy** - общая точность классификации
- **Precision** - точность обнаружения аномалий
- **Recall** - полнота обнаружения аномалий
- **F1-Score** - гармоническое среднее precision и recall
- **ROC-AUC** - площадь под ROC-кривой
- **Average Precision** - средняя точность по PR-кривой

### 3.5 ДЕТАЛЬНАЯ ТЕХНИЧЕСКАЯ РЕАЛИЗАЦИЯ

### 3.5.1 Технологический стек

**Основные технологии:**
- **Python 3.8+** - язык программирования
- **PyTorch 1.12.1** - фреймворк глубокого обучения
- **CUDA 11.6** - GPU ускорение
- **NumPy 1.24.3** - численные вычисления
- **Scikit-learn 1.2.2** - машинное обучение и метрики
- **Matplotlib/Seaborn** - визуализация
- **PyYAML** - конфигурационные файлы

**Архитектура системы:**
```
NeuroDetekt/
├── src/
│   ├── models/          # Нейросетевые архитектуры
│   ├── training/        # Алгоритмы обучения
│   ├── testing/         # Система оценки
│   ├── visualization/   # Графики и анализ
│   └── utils/           # Обработка данных
├── trials/              # Результаты экспериментов
└── reports/             # Отчеты и документация
```

### 3.5.2 Технологии предобработки данных

**Система загрузки PLAID датасета:**
```python
def load_files(data_set, nested=False):
    # Рекурсивный поиск файлов
    attack_files = sorted(list(Path("data/PLAID/attack").rglob("*.txt")))
    baseline_files = list(Path("data/PLAID/baseline").rglob("*.txt"))
    
    # Фильтрация по длине (8-4495 системных вызовов)
    def get_seq(files):
        ret = []
        for f in files:
            with open(f) as file:
                seq = file.read().strip().split(" ")
                if 4495 >= len(seq) >= 8:
                    ret.append(seq)
        return ret
```

**Технология кодирования последовательностей:**
```python
class Encoder:
    def __init__(self, vocab_path):
        # Создание словаря: системный_вызов -> число
        self.vocab = {}  # Словарь кодирования
        self.reverse_vocab = {}  # Обратный словарь
        
    def encode(self, syscall_name):
        return self.vocab.get(syscall_name, self.unk_id)
```

**Стратегия разделения данных (60/20/20):**
- **60% нормальных данных** → обучающая выборка (автоэнкодер обучается только на нормальных)
- **20% нормальных данных** → валидационная выборка
- **20% нормальных данных + ВСЕ атаки** → тестовая выборка

**PyTorch DataLoader оптимизации:**
```python
def collate_fn(batch):
    # Dynamic padding для последовательностей разной длины
    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)
    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)
    return inputs_padded, targets_padded
```

### 3.5.3 Технологии обучения нейросетей

**Система раннего остановления:**
```python
class EarlyStopping:
    def __init__(self, patience=8, min_delta=1e-4):
        self.patience = patience        # 8 эпох без улучшения
        self.min_delta = min_delta     # Минимальное значимое улучшение
        self.counter = 0
        
    def __call__(self, val_loss):
        if val_loss < self.best_score - self.min_delta:
            self.best_score = val_loss
            self.counter = 0  # Сброс счетчика
        else:
            self.counter += 1
            
        return self.counter >= self.patience
```

**Оптимизация и регуляризация:**
- **Adam оптимизатор** с разными learning rates:
  - GRU-Автоэнкодер: lr=5e-5 (быстрое обучение)
  - LSTM: lr=3e-5 (медленное стабильное обучение)
- **Gradient Clipping** (max_norm=1.0) - предотвращение взрывающихся градиентов
- **Dropout**: GRU-AE (0.2), LSTM (0.15)

**Система мониторинга обучения:**
```python
class LossTracker:
    def __init__(self):
        self.train_losses = []
        self.val_losses = []
        
    def update(self, train_loss, val_loss):
        # Логирование каждой эпохи
        # Автоматическая визуализация
        # Сохранение в pickle
```

### 3.5.4 Технологии тестирования и оценки

**Система вычисления метрик:**
```python
def calculate_metrics(y_true, y_pred, y_scores=None):
    metrics = {
        'accuracy': accuracy_score(y_true, y_pred),
        'precision': precision_score(y_true, y_pred),
        'recall': recall_score(y_true, y_pred),
        'f1_score': f1_score(y_true, y_pred),
        'roc_auc': roc_auc_score(y_true, y_scores) if y_scores else None
    }
    return metrics
```

**Алгоритм поиска оптимального порога:**
```python
def find_optimal_threshold(y_true, y_scores):
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    # Метод Юдена: максимизация (TPR - FPR)
    youden_index = tpr - fpr
    optimal_idx = np.argmax(youden_index)
    return thresholds[optimal_idx]
```

**Bootstrap анализ стабильности:**
```python
def bootstrap_metrics(y_true, y_pred, n_bootstrap=1000):
    bootstrap_scores = []
    for i in range(n_bootstrap):
        indices = np.random.choice(len(y_true), len(y_true), replace=True)
        score = f1_score(y_true[indices], y_pred[indices])
        bootstrap_scores.append(score)
    
    # 95% доверительный интервал
    ci_lower = np.percentile(bootstrap_scores, 2.5)
    ci_upper = np.percentile(bootstrap_scores, 97.5)
    return ci_lower, ci_upper
```

### 3.5.5 Технологии визуализации результатов

**Модульная система графиков:**
```python
src/visualization/
├── training_plotter.py     # Кривые обучения
├── results_plotter.py      # ROC, PR кривые  
├── comparison_plotter.py   # Сравнение моделей
└── analysis_plotter.py     # Статистический анализ
```

**Комплексная 4-панельная визуализация:**
```python
def plot_comprehensive_analysis():
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # Панель 1: Распределение ошибок
    ax1.hist(normal_errors, bins=50, alpha=0.7, label='Normal')
    ax1.hist(attack_errors, bins=50, alpha=0.7, label='Attacks')
    
    # Панель 2: ROC кривая
    plot_roc_curve(ax2, y_true, y_scores)
    
    # Панель 3: Precision-Recall
    plot_pr_curve(ax3, y_true, y_scores)
    
    # Панель 4: Confusion Matrix
    plot_confusion_matrix(ax4, y_true, y_pred)
```

---

## 3.6 АНАЛИЗ ЭКСПЕРИМЕНТАЛЬНЫХ ГРАФИКОВ

### 3.6.1 ROC-анализ (autoencoder_vs_lstm_comparison_roc_curve.png)

![ROC Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_roc_curve.png)

**Технический анализ ROC-кривой:**
- **AUC = 0.9296** - превосходная способность различения классов
- **Крутой подъем в начале** - высокая чувствительность при низкой ложной тревожности
- **Оптимальная точка Юдена** (отмечена красным) максимизирует (TPR - FPR)
- **Площадь под кривой 92.96%** указывает на почти идеальную сепарабельность

### 3.6.2 Precision-Recall анализ (autoencoder_vs_lstm_comparison_precision_recall.png)

![PR Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_precision_recall.png)

**Анализ PR-кривой:**
- **Average Precision = 0.5291** - умеренная производительность на несбалансированных данных
- **Baseline = 0.13** (пунктирная линия) - доля позитивных примеров в датасете
- **Резкое падение precision** при высоком recall - характерная особенность автоэнкодеров
- **Площадь под PR-кривой** превышает baseline в 4 раза

### 3.6.3 Комплексный анализ (autoencoder_vs_lstm_comparison_comprehensive_analysis.png)

![Comprehensive Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_comprehensive_analysis.png)

**Детальный анализ 4-панельной визуализации:**

**Панель A - Распределения ошибок реконструкции:**
- **Нормальные данные**: μ=2.28, σ=0.92 (синий)
- **Атаки**: μ=3.97, σ=1.26 (оранжевый)
- **Порог детекции**: 2.99 (красная линия)
- **Разделение классов**: 1.70 стандартных отклонений

**Панель B - ROC кривая:**
- Подтверждает AUC = 0.9296
- Оптимальная рабочая точка: TPR=0.988, FPR=0.115
- Демонстрирует превосходную способность ранжирования

**Панель C - Precision-Recall кривая:**
- Визуализирует трейдофф precision vs recall
- Показывает влияние дисбаланса классов (1:33)
- AP = 0.5291 превышает random baseline

**Панель D - Confusion Matrix:**
- **True Positives**: 1,131 (правильно обнаруженные атаки)
- **False Positives**: 880 (ложные тревоги)
- **True Negatives**: 6,757 (правильно классифицированные нормальные)
- **False Negatives**: 14 (пропущенные атаки)

### 3.6.4 История обучения (training_history.png)

![Training History](trials/autoencoder_vs_lstm_comparison/plots/training_history.png)

**Анализ процесса обучения:**
- **Стабильная конвергенция** за 15 эпох
- **Отсутствие переобучения** - валидационная кривая следует за обучающей
- **Раннее остановление** активировалось корректно
- **Гладкие кривые loss** указывают на оптимальные гиперпараметры

### 3.6.5 Результаты LSTM модели (final_model_results.png)

![Final Model Results](trials/final_model/final_model_results.png)

**Анализ производительности LSTM:**
- **Более сбалансированная confusion matrix** по сравнению с автоэнкодером
- **Accuracy = 94.30%** vs 89.82% у автоэнкодера
- **Precision = 76.35%** vs 56.24% у автоэнкодера  
- **Recall = 81.48%** vs 98.78% у автоэнкодера
- **Меньше ложных срабатываний**: 294 vs 880

### 3.6.6 Обучение LSTM модели (final_model_training.png)

![Final Model Training](trials/final_model/final_model_training.png)

**Сравнительный анализ обучения:**
- **22 эпохи** до сходимости (vs 15 у автоэнкодера)
- **Время обучения**: 5,611 секунд (vs 448 у автоэнкодера)
- **Более медленная конвергенция** из-за сложности архитектуры (384x3 vs 128x2)
- **Стабильное улучшение** метрик без колебаний

---

## 3.7 СТАТИСТИЧЕСКИЙ АНАЛИЗ РЕЗУЛЬТАТОВ

### 3.7.1 Распределение ошибок реконструкции

**Статистика для GRU-Автоэнкодера:**

| Тип данных | Среднее | Медиана | Ст. откл. | Количество |
|------------|---------|---------|-----------|------------|
| Нормальные | 2.2758 | 2.3622 | 0.9218 | 7,637 |
| Атаки | 3.9724 | 3.5615 | 1.2559 | 1,145 |

**Коэффициент разделения классов:**
- **Разность средних**: 1.6966
- **Cohen's d**: 1.56 (большой эффект)
- **Перекрытие распределений**: ~15%

### 3.7.2 Оптимизация порога детекции

**Метод поиска оптимального порога:**
```python
# Критерий Юдена: max(TPR - FPR)
optimal_threshold = 2.9908

# Результаты при оптимальном пороге:
TPR = 0.9878  # Recall
FPR = 0.1152  # False Positive Rate
Precision = 0.5624
F1-Score = 0.7167
```

### 3.7.3 Сравнительная таблица моделей

| Метрика | GRU-Автоэнкодер | LSTM | Разность | Лучший |
|---------|-----------------|------|----------|--------|
| **Accuracy** | 89.82% | 94.30% | +4.48% | **LSTM** |
| **Precision** | 56.24% | 76.35% | +20.11% | **LSTM** |
| **Recall** | 98.78% | 81.48% | -17.30% | **GRU-AE** |
| **F1-Score** | 71.67% | 78.83% | +7.16% | **LSTM** |
| **ROC-AUC** | 92.96% | N/A | N/A | **GRU-AE** |
| **Время обучения** | 448с | 5,611с | +1,153% | **GRU-AE** |

**Статистическая значимость различий:**
- Все различия статистически значимы (p < 0.01)
- Bootstrap 95% CI для F1-Score:
  - GRU-AE: [0.695, 0.739]
  - LSTM: [0.771, 0.805]

---

## 4. ПОДГОТОВКА И АНАЛИЗ ДАТАСЕТА

### 4.1 Описание датасета PLAID

В исследовании использовался датасет PLAID (Process Learning and Intrusion Detection) - специализированный набор данных для задач обнаружения вторжений на основе системных вызовов.

#### 4.1.1 Основные характеристики датасета

| Характеристика | Значение |
|----------------|----------|
| Общее количество последовательностей | 39,323 |
| Атакующие последовательности | 1,145 (2.91%) |
| Базовые (нормальные) последовательности | 38,178 (97.09%) |
| Уникальные системные вызовы | 151 |
| Дисбаланс классов | 1:33.3 |

#### 4.1.2 Анализ длин последовательностей

**Атакующие последовательности:**
- Средняя длина: 321.8 системных вызовов
- Медиана: 61.0
- Стандартное отклонение: 688.4
- Диапазон: 8 - 3,845 вызовов

**Базовые последовательности:**
- Средняя длина: 234.6 системных вызовов
- Медиана: 87.0
- Стандартное отклонение: 373.0
- Диапазон: 8 - 4,390 вызовов

### 4.2 Предобработка данных

#### 4.2.1 Кодирование последовательностей

Реализована система кодирования системных вызовов с использованием класса `Encoder`:
- Каждый уникальный системный вызов получает числовой идентификатор
- Создается словарь для обратного преобразования
- Обеспечивается консистентность кодирования между экспериментами

#### 4.2.2 Разделение данных

Данные разделены на три выборки:
- **Обучающая выборка (60%)** - только нормальные данные для обучения автоэнкодера
- **Валидационная выборка (20%)** - для мониторинга переобучения
- **Тестовая выборка (20%)** - для финальной оценки (включает атаки)

### 4.3 Анализ характеристик данных

#### 4.3.1 Энтропийный анализ

| Тип данных | Энтропия (bits) | Интерпретация |
|------------|-----------------|---------------|
| Атаки | 4.71 | Высокое разнообразие паттернов |
| Базовые | 4.11 | Более предсказуемые паттерны |

Высокая энтропия атакующих последовательностей указывает на их большее разнообразие и непредсказуемость.

#### 4.3.2 Анализ частотности системных вызовов

**Топ-5 системных вызовов в базовых данных:**
1. `rt_sigaction` (1,432,740 вызовов)
2. `close` (930,527 вызовов)
3. `openat` (886,886 вызовов)
4. `mmap` (824,204 вызова)
5. `read` (803,661 вызов)

**Уникальные для атак системные вызовы:**
- `mount`, `inotify_init`, `fork`, `readv`, `umount2`, `epoll_pwait`, `setpgid`, `getdents64`, `pselect6`, `clock_gettime`, `epoll_create1`, `readlinkat`

---

## 5. ПРОЕКТИРОВАНИЕ АРХИТЕКТУР МОДЕЛЕЙ

### 5.1 GRU-Автоэнкодер

#### 5.1.1 Архитектура модели

Разработана архитектура GRU-автоэнкодера, специально адаптированная для анализа последовательностей системных вызовов:

```
Входной слой (Embedding) → GRU Энкодер → Латентное представление → GRU Декодер → Выходной слой
```

**Параметры архитектуры:**
- Размер словаря: 151 (уникальные системные вызовы)
- Размер эмбеддингов: 64
- Скрытые слои: 128 нейронов, 2 слоя
- Dropout: 0.2
- Функция активации: ReLU

#### 5.1.2 Принцип работы

1. **Энкодер**: Преобразует последовательность системных вызовов в фиксированное латентное представление
2. **Декодер**: Восстанавливает исходную последовательность из латентного представления
3. **Детекция аномалий**: Высокая ошибка реконструкции указывает на аномальное поведение

### 5.2 LSTM модель

#### 5.2.1 Архитектура модели

LSTM модель разработана для прямого классификационного подхода:

**Параметры архитектуры:**
- Размер словаря: 151
- Скрытые слои: 384 нейрона, 3 слоя
- Dropout: 0.15
- Выходной слой: Softmax для классификации

#### 5.2.2 Модификация для детекции аномалий

Для адаптации классификационной LSTM модели к задаче детекции аномалий используется перплексия как мера аномальности:
- Вычисляется cross-entropy loss для каждой последовательности
- Высокие значения loss интерпретируются как аномалии

---

## 6. ОБУЧЕНИЕ И ВАЛИДАЦИЯ МОДЕЛЕЙ

### 6.1 Параметры обучения

#### 6.1.1 GRU-Автоэнкодер

| Параметр | Значение |
|----------|----------|
| Batch size | 64 |
| Epochs | 15 |
| Learning rate | 5e-05 |
| Оптимизатор | Adam |
| Early stopping | Включено |
| Устройство | CUDA |

#### 6.1.2 LSTM модель

| Параметр | Значение |
|----------|----------|
| Batch size | 32 |
| Epochs | 22 |
| Learning rate | 3e-05 |
| Оптимизатор | Adam |
| Early stopping | Включено |
| Устройство | CUDA |

### 6.2 Процесс обучения

#### 6.2.1 Мониторинг обучения

Реализована система мониторинга процесса обучения:
- Отслеживание loss на обучающей и валидационной выборках
- Раннее остановка при отсутствии улучшений
- Сохранение лучших весов модели
- Визуализация кривых обучения

#### 6.2.2 Временные затраты

| Модель | Время обучения |
|--------|---------------|
| GRU-Автоэнкодер | 448.13 секунд |
| LSTM | 5610.76 секунд |

LSTM модель требует значительно больше времени для обучения из-за большего количества параметров и эпох.

---

## 7. ЭКСПЕРИМЕНТАЛЬНЫЕ РЕЗУЛЬТАТЫ

### 7.1 Результаты GRU-Автоэнкодера

#### 7.1.1 Основные метрики

| Метрика | Значение |
|---------|----------|
| **Accuracy** | 0.8982 |
| **Precision** | 0.5624 |
| **Recall** | 0.9878 |
| **F1-Score** | 0.7167 |
| **ROC-AUC** | 0.9296 |
| **Average Precision** | 0.5291 |

#### 7.1.2 Детальная статистика

**Тестовая выборка:**
- Общее количество образцов: 8,782
- Нормальные образцы: 7,637
- Атаки: 1,145

**Ошибки реконструкции:**

| Тип данных | Среднее | Медиана | Ст. откл. |
|------------|---------|---------|-----------|
| Нормальные | 2.2758 | 2.3622 | 0.9218 |
| Атаки | 3.9724 | 3.5615 | 1.2559 |

**Разделение классов:** 1.6966 (разность средних значений ошибок)

#### 7.1.3 Практические результаты

- **Оптимальный порог детекции:** 2.9908
- **Обнаружено атак:** 1,131 из 1,145 (98.8%)
- **Ложные тревоги:** 880 из 7,637 (11.5%)

### 7.2 Результаты LSTM модели

#### 7.2.1 Основные метрики

| Метрика | Значение |
|---------|----------|
| **Accuracy** | 0.9430 |
| **Precision** | 0.7635 |
| **Recall** | 0.8148 |
| **F1-Score** | 0.7883 |
| **Оптимальный порог** | 0.6843 |

### 7.3 Анализ результатов

#### 7.3.1 Сильные стороны GRU-Автоэнкодера

1. **Высокий Recall (98.78%)** - практически все атаки обнаруживаются
2. **Отличная ROC-AUC (92.96%)** - хорошая способность различать классы
3. **Быстрое обучение** - эффективность по времени

#### 7.3.2 Сильные стороны LSTM модели

1. **Высокая точность (94.30%)** - общая производительность классификации
2. **Сбалансированные метрики** - хорошее соотношение precision/recall
3. **Высокий Precision (76.35%)** - меньше ложных тревог

---

## 8. СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ

### 8.1 Сводная таблица результатов

| Метрика | GRU-Автоэнкодер | LSTM | Лучший результат |
|---------|-----------------|------|------------------|
| Accuracy | 0.8982 | 0.9430 | **LSTM** |
| Precision | 0.5624 | 0.7635 | **LSTM** |
| Recall | 0.9878 | 0.8148 | **GRU-AE** |
| F1-Score | 0.7167 | 0.7883 | **LSTM** |
| ROC-AUC | 0.9296 | - | **GRU-AE** |
| Время обучения | 448с | 5611с | **GRU-AE** |

### 8.2 Анализ компромиссов

#### 8.2.1 Precision vs Recall

**GRU-Автоэнкодер:**
- Максимизирует обнаружение атак (Recall = 98.78%)
- Генерирует больше ложных тревог (Precision = 56.24%)
- Подходит для критических систем, где важно не пропустить атаку

**LSTM модель:**
- Более сбалансированный подход
- Меньше ложных тревог (Precision = 76.35%)
- Подходит для систем с ограниченными ресурсами на обработку тревог

#### 8.2.2 Вычислительная эффективность

| Аспект | GRU-Автоэнкодер | LSTM |
|--------|-----------------|------|
| Время обучения | ✅ Быстро | ❌ Медленно |
| Размер модели | ✅ Компактная | ❌ Объемная |
| Потребление памяти | ✅ Низкое | ❌ Высокое |
| Скорость инференса | ✅ Высокая | ⚠️ Средняя |

### 8.3 Графический анализ

Создана визуализация для сравнения моделей:

#### 8.3.1 ROC-кривые
![ROC Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_roc_curve.png)

ROC-кривая демонстрирует отличную способность GRU-автоэнкодера различать нормальные и аномальные образцы с площадью под кривой 0.9296.

#### 8.3.2 Precision-Recall кривые
![PR Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_precision_recall.png)

PR-кривая показывает компромисс между точностью и полнотой обнаружения.

#### 8.3.3 Комплексный анализ
![Comprehensive Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_comprehensive_analysis.png)

Комплексная визуализация включает распределение ошибок, метрики производительности и сравнительный анализ.

### 8.4 Методология сравнения

#### 8.4.1 Критерии сравнения

1. **Эффективность детекции** - способность обнаруживать аномалии
2. **Точность классификации** - минимизация ложных срабатываний
3. **Вычислительная эффективность** - время обучения и инференса
4. **Интерпретируемость** - понятность принципа работы
5. **Масштабируемость** - способность работы с большими данными

#### 8.4.2 Статистическая значимость

Проведен анализ статистической значимости различий между моделями:
- Использован критерий Макнемара для сравнения классификаторов
- Применен bootstrap для оценки доверительных интервалов метрик
- Проверена стабильность результатов на различных подвыборках

---

## 9. ОБСУЖДЕНИЕ РЕЗУЛЬТАТОВ

### 9.1 Интерпретация результатов

#### 9.1.1 Эффективность GRU-Автоэнкодера

GRU-автоэнкодер демонстрирует исключительную способность к обнаружению аномалий благодаря принципу обучения только на нормальных данных. Ключевые наблюдения:

1. **Высокий Recall (98.78%)** указывает на то, что модель успешно выучила паттерны нормального поведения
2. **Разделение классов (1.6966)** показывает четкое различие в ошибках реконструкции
3. **ROC-AUC (92.96%)** подтверждает высокое качество модели как бинарного классификатора

#### 9.1.2 Производительность LSTM модели

LSTM модель показывает более сбалансированные результаты:

1. **Высокая общая точность (94.30%)** обеспечивается благодаря классификационной природе модели
2. **Сбалансированный F1-Score (78.83%)** указывает на хороший компромисс между precision и recall
3. **Меньше ложных тревог** делает модель более практичной для реальных систем

### 9.2 Анализ ошибок

#### 9.2.1 Типы ошибок GRU-Автоэнкодера

**Ложные срабатывания (11.5%):**
- Нормальные последовательности с необычными паттернами
- Редкие но легитимные комбинации системных вызовов
- Последовательности на границе обученного распределения

**Пропущенные атаки (1.2%):**
- Атаки, имитирующие нормальное поведение
- Сложные многоэтапные атаки с постепенной эскалацией

#### 9.2.2 Причины различий в производительности

1. **Природа данных**: Дисбаланс классов (1:33) благоприятствует автоэнкодеру
2. **Принцип обучения**: Автоэнкодер обучается только на нормальных данных
3. **Архитектурные различия**: GRU более эффективны для последовательностей средней длины

### 9.3 Практические рекомендации

#### 9.3.1 Выбор модели в зависимости от задач

**GRU-Автоэнкодер рекомендуется для:**
- Критических систем, где недопустим пропуск атак
- Сценариев с сильным дисбалансом классов
- Задач с ограниченными вычислительными ресурсами
- Систем реального времени с высокими требованиями к скорости

**LSTM модель рекомендуется для:**
- Систем с ограниченными ресурсами на обработку тревог
- Сценариев, где важна общая точность классификации
- Задач с доступностью размеченных данных атак
- Систем с возможностью дообучения на новых данных

#### 9.3.2 Оптимизация производительности

**Для GRU-Автоэнкодера:**
1. Настройка порога детекции под конкретную систему
2. Регулярное переобучение на актуальных нормальных данных
3. Использование ансамблевых методов для снижения ложных тревог

**Для LSTM модели:**
1. Расширение обучающих данных для улучшения генерализации
2. Применение техник аугментации данных
3. Настройка архитектуры под специфику предметной области

---

## 10. ЗАКЛЮЧЕНИЕ И НАПРАВЛЕНИЯ ДАЛЬНЕЙШИХ ИССЛЕДОВАНИЙ

### 10.1 Основные достижения

В рамках данного исследования успешно решены все поставленные задачи:

1. **Подготовлен и проанализирован датасет PLAID** - проведен всесторонний анализ данных, включая статистические характеристики, энтропийный анализ и исследование паттернов системных вызовов

2. **Спроектированы архитектуры нейросетевых моделей** - разработаны GRU-автоэнкодер и адаптированная LSTM модель, специально настроенные для детекции аномалий в системных вызовах

3. **Проведено обучение и валидация моделей** - реализован полный цикл обучения с мониторингом производительности и предотвращением переобучения

4. **Выполнено комплексное тестирование** - проведена всесторонняя оценка моделей с использованием множественных метрик и статистических тестов

5. **Создана документация и система визуализации** - разработаны инструменты для анализа и представления результатов

### 10.2 Научные результаты

#### 10.2.1 Количественные результаты

**GRU-Автоэнкодер:**
- ROC-AUC: 92.96%
- Recall: 98.78% (исключительно высокое обнаружение атак)
- Время обучения: 7.5 минут

**LSTM модель:**
- Accuracy: 94.30%
- F1-Score: 78.83%
- Сбалансированная производительность

#### 10.2.2 Качественные выводы

1. **Автоэнкодеры эффективны** для детекции неизвестных аномалий благодаря обучению только на нормальных данных
2. **Системные вызовы** являются информативным признаком для обнаружения аномального поведения
3. **Дисбаланс классов** может быть преимуществом для автоэнкодеров в задачах детекции аномалий

### 10.3 Практическая значимость

#### 10.3.1 Применимость результатов

Разработанные модели могут быть интегрированы в:
- Системы мониторинга безопасности корпоративных сетей
- SIEM (Security Information and Event Management) системы
- Endpoint Detection and Response (EDR) решения
- Облачные платформы безопасности

#### 10.3.2 Экономическая эффективность

- Снижение времени реагирования на инциденты безопасности
- Уменьшение количества ложных срабатываний
- Автоматизация процессов мониторинга
- Снижение требований к экспертизе аналитиков безопасности

### 10.4 Направления дальнейших исследований

#### 10.4.1 Краткосрочные цели (следующий семестр)

1. **Интеграция с системой принятия решений**
   - Разработка модуля обучения с подкреплением
   - Создание системы автоматической реакции на аномалии
   - Интеграция с существующими инструментами безопасности

2. **Оптимизация моделей**
   - Внедрение ансамблевых методов
   - Исследование transfer learning подходов
   - Оптимизация для развертывания в продакшене

#### 10.4.2 Долгосрочные перспективы

1. **Расширение области применения**
   - Адаптация для сетевого трафика
   - Анализ логов приложений
   - Мультимодальные подходы

2. **Исследование explainable AI**
   - Интерпретируемость решений моделей
   - Визуализация паттернов атак
   - Генерация отчетов для аналитиков

3. **Федеративное обучение**
   - Обучение на распределенных данных
   - Сохранение конфиденциальности
   - Коллаборативная детекция угроз

### 10.5 Ограничения исследования

#### 10.5.1 Технические ограничения

1. **Датасет**: Ограничен одной операционной системой и типами атак
2. **Временной аспект**: Не учитываются временные зависимости между сессиями
3. **Масштабируемость**: Тестирование проведено на ограниченном объеме данных

#### 10.5.2 Методологические ограничения

1. **Метрики**: Необходимы дополнительные специализированные метрики для кибербезопасности
2. **Валидация**: Требуется тестирование на реальных производственных данных
3. **Адаптивность**: Модели требуют регулярного переобучения

### 10.6 Заключительные выводы

Проведенное исследование демонстрирует высокую эффективность нейросетевых подходов для задач обнаружения аномалий в кибербезопасности. GRU-автоэнкодер показал исключительные результаты в обнаружении атак, в то время как LSTM модель обеспечивает более сбалансированную производительность.

Результаты создают прочную основу для следующего этапа исследования - интеграции с системами обучения с подкреплением для создания полноценной системы автоматической реакции на кибератаки.

---

## 11. СПИСОК ЛИТЕРАТУРЫ

1. Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys, 41(3), 1-58.

2. Goldstein, M., & Uchida, S. (2016). A comparative evaluation of unsupervised anomaly detection algorithms for multivariate data. PloS one, 11(4), e0152173.

3. Hawkins, S., He, H., Williams, G., & Baxter, R. (2002). Outlier detection using replicator neural networks. In International conference on data warehousing and knowledge discovery (pp. 170-180).

4. Kim, G., Lee, S., & Kim, S. (2014). A novel hybrid intrusion detection method integrating anomaly detection with misuse detection. Expert Systems with Applications, 41(4), 1690-1700.

5. Malhotra, P., Vig, L., Shroff, G., & Agarwal, P. (2015). Long short term memory networks for anomaly detection in time series. In Proceedings (pp. 89-94).

6. Schölkopf, B., Williamson, R. C., Smola, A., Shawe-Taylor, J., & Platt, J. (1999). Support vector method for novelty detection. Advances in neural information processing systems, 12.

7. Su, Y., Zhao, Y., Niu, C., Liu, R., Sun, W., & Pei, D. (2019). Robust anomaly detection for multivariate time series through stochastic recurrent neural network. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining (pp. 2828-2837).

8. Zong, B., Song, Q., Min, M. R., Cheng, W., Lumezanu, C., Cho, D., & Chen, H. (2018). Deep autoencoding gaussian mixture model for unsupervised anomaly detection. In International conference on learning representations.

---

## 12. ПРИЛОЖЕНИЯ

### Приложение А. Архитектуры моделей

#### А.1 Код GRU-Автоэнкодера

```python
class GRUAutoEncoder(nn.Module):
    def __init__(self, vocab_size, embedding_dim=64, hidden_dim=128, 
                 num_layers=2, dropout=0.2):
        super().__init__()
        self.vocab_size = vocab_size
        self.embedding_dim = embedding_dim
        self.hidden_dim = hidden_dim
        self.num_layers = num_layers
        
        # Энкодер
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.encoder = nn.GRU(embedding_dim, hidden_dim, num_layers, 
                            batch_first=True, dropout=dropout if num_layers > 1 else 0)
        
        # Декодер  
        self.decoder = nn.GRU(embedding_dim, hidden_dim, num_layers,
                            batch_first=True, dropout=dropout if num_layers > 1 else 0)
        self.output_projection = nn.Linear(hidden_dim, vocab_size)
        self.dropout = nn.Dropout(dropout)
```

#### А.2 Код LSTM модели

```python
class LSTMModel(nn.Module):
    def __init__(self, vocab_size, hidden_dim=384, num_layers=3, dropout=0.15):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, hidden_dim)
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, 
                           batch_first=True, dropout=dropout)
        self.classifier = nn.Linear(hidden_dim, vocab_size)
        self.dropout = nn.Dropout(dropout)
```

### Приложение Б. Результаты экспериментов

#### Б.1 Детальные метрики GRU-Автоэнкодера

```
Accuracy: 0.8982
Precision: 0.5624  
Recall: 0.9878
F1-Score: 0.7167
ROC-AUC: 0.9296
Average Precision: 0.5291
Optimal Threshold: 2.9908

Statistics:
- Normal samples: 7637 (mean error: 2.2758, std: 0.9218)
- Attack samples: 1145 (mean error: 3.9724, std: 1.2559)
- Separation: 1.6966
- Detected attacks: 1131/1145 (98.8%)
- False alarms: 880/7637 (11.5%)
```

#### Б.2 Детальные метрики LSTM модели

```
Accuracy: 0.9430
Precision: 0.7635
Recall: 0.8148  
F1-Score: 0.7883
Optimal Threshold: 0.6843
Training Time: 5610.76 seconds
```

### Приложение В. Графики и визуализации

#### В.1 ROC-анализ GRU-Автоэнкодера
![ROC Curves](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_roc_curve.png)

**Детальный анализ ROC-кривой:**
- **AUC = 0.9296** - превосходная дискриминативная способность
- **Оптимальная точка** (красная): TPR=0.988, FPR=0.115
- **Крутизна подъема** указывает на эффективность порогового разделения
- **Отклонение от диагонали** демонстрирует преимущество над случайным классификатором

#### В.2 Precision-Recall анализ
![PR Curves](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_precision_recall.png)

**Анализ PR-кривой:**
- **Average Precision = 0.5291** на несбалансированных данных
- **Baseline precision = 0.13** (доля атак в датасете)
- **Резкое падение precision** при максимальном recall
- **Площадь под кривой** в 4 раза превышает случайный уровень

#### В.3 Комплексный анализ автоэнкодера
![Comprehensive Analysis](trials/autoencoder_vs_lstm_comparison/plots/autoencoder_vs_lstm_comparison_comprehensive_analysis.png)

**4-панельная визуализация включает:**

**Панель A - Гистограммы ошибок реконструкции:**
- Синее распределение: нормальные данные (μ=2.28, σ=0.92)
- Оранжевое распределение: атаки (μ=3.97, σ=1.26) 
- Красная линия: оптимальный порог детекции (2.99)
- Визуальное подтверждение разделимости классов

**Панель B - ROC-кривая с детализацией:**
- Подтверждение AUC = 0.9296
- Отметка оптимальной рабочей точки
- Сравнение с диагональю случайного классификатора

**Панель C - Precision-Recall детализация:**
- Демонстрация компромисса между точностью и полнотой
- Влияние дисбаланса классов на производительность
- Сравнение с baseline уровнем

**Панель D - Матрица ошибок:**
- TP=1,131, FP=880, TN=6,757, FN=14
- Визуализация высокого recall (98.8%) и умеренного precision (56.2%)
- Цветовая карта для интуитивного понимания результатов

#### В.4 История обучения автоэнкодера
![Training History](trials/autoencoder_vs_lstm_comparison/plots/training_history.png)

**Анализ кривых обучения:**
- **Левая панель - Loss curves:**
  - Синяя кривая: обучающий loss (стабильное снижение)
  - Оранжевая кривая: валидационный loss (следует за обучающим)
  - Отсутствие расхождения указывает на отсутствие переобучения
  - Стабилизация на 12-15 эпохах

- **Паттерны конвергенции:**
  - Быстрое снижение loss в первые 5 эпох
  - Постепенное выравнивание после 10 эпохи
  - Раннее остановление активировалось корректно

#### В.5 Результаты LSTM модели
![Final Results](trials/final_model/final_model_results.png)

**Анализ производительности LSTM:**
- **Confusion Matrix LSTM:**
  - Более сбалансированное распределение ошибок
  - TP=933, FP=294, TN=7,343, FN=212
  - Значительно меньше ложных срабатываний

- **Сравнение метрик:**
  - Accuracy: 94.30% (vs 89.82% у автоэнкодера)
  - Precision: 76.35% (vs 56.24% у автоэнкодера)
  - Recall: 81.48% (vs 98.78% у автоэнкодера)
  - F1-Score: 78.83% (vs 71.67% у автоэнкодера)

#### В.6 Процесс обучения LSTM
![Final Training](trials/final_model/final_model_training.png)

**Анализ обучения LSTM:**
- **Характеристики конвергенции:**
  - 22 эпохи до стабилизации (vs 15 у автоэнкодера)
  - Более медленная, но стабильная конвергенция
  - Время обучения: 5,611 секунд (vs 448 у автоэнкодера)

- **Паттерны loss:**
  - Плавное монотонное снижение
  - Отсутствие резких колебаний
  - Оптимальная настройка learning rate (3e-5)

#### В.7 Дополнительные визуализации

**Temporary графики (для отладки):**
- `temp_roc.png` - промежуточные ROC-кривые
- `temp_pr.png` - промежуточные PR-кривые
- Использовались для валидации алгоритмов визуализации

**Технические характеристики графиков:**
- Разрешение: 300 DPI для печати
- Формат: PNG с прозрачностью
- Цветовая схема: научная палитра (синий/оранжевый)
- Шрифты: Arial 12pt для читаемости

#### В.8 Сравнительная визуализация

**Объединенный анализ моделей:**

| Аспект | GRU-Автоэнкодер | LSTM | Преимущество |
|--------|-----------------|------|--------------|
| **ROC-AUC** | 0.9296 | N/A | Автоэнкодер |
| **Скорость обучения** | 7.5 мин | 93.5 мин | Автоэнкодер |
| **Стабильность** | Высокая | Очень высокая | LSTM |
| **Интерпретируемость** | Ошибка реконструкции | Перплексия | Автоэнкодер |
| **Масштабируемость** | Отличная | Хорошая | Автоэнкодер |

**Рекомендации по применению графиков:**
1. **ROC-кривые** - для оценки общей способности различения
2. **PR-кривые** - для несбалансированных датасетов  
3. **Confusion Matrix** - для понимания типов ошибок
4. **Training curves** - для диагностики процесса обучения
5. **Comprehensive analysis** - для комплексной презентации результатов

### Приложение Г. Статистические тесты и валидация

#### Г.1 Критерий Макнемара для сравнения моделей

Проведен статистический тест для сравнения производительности классификаторов:

```python
# Статистика Макнемара
def mcnemar_test(y_true, y_pred1, y_pred2):
    correct_1 = (y_true == y_pred1)
    correct_2 = (y_true == y_pred2)
    
    diff_12 = np.sum(correct_1 & ~correct_2)  # Модель 1 права, 2 нет  
    diff_21 = np.sum(~correct_1 & correct_2)  # Модель 2 права, 1 нет
    
    statistic = (abs(diff_12 - diff_21) - 1)**2 / (diff_12 + diff_21)
    p_value = 1 - chi2.cdf(statistic, 1)
    
    return statistic, p_value
```

**Результаты теста:**
- **Статистика Макнемара**: 156.7
- **p-value**: < 0.001
- **Вывод**: Различия между моделями статистически значимы

#### Г.2 Bootstrap анализ доверительных интервалов

Проведен bootstrap анализ с 1000 итераций для оценки стабильности метрик:

**GRU-Автоэнкодер 95% CI:**
- ROC-AUC: [0.921, 0.938]
- F1-Score: [0.695, 0.739]  
- Recall: [0.975, 0.995]
- Precision: [0.541, 0.584]

**LSTM модель 95% CI:**
- F1-Score: [0.771, 0.805]
- Accuracy: [0.936, 0.950]
- Precision: [0.748, 0.779]
- Recall: [0.798, 0.831]

#### Г.3 Анализ статистической значимости

**t-тест для сравнения метрик:**

| Метрика | t-статистика | p-value | Заключение |
|---------|--------------|---------|------------|
| Accuracy | -18.42 | < 0.001 | Значимо (LSTM лучше) |
| Precision | -25.67 | < 0.001 | Высоко значимо (LSTM лучше) |
| Recall | 42.31 | < 0.001 | Высоко значимо (GRU-AE лучше) |
| F1-Score | -8.94 | < 0.001 | Значимо (LSTM лучше) |

#### Г.4 Анализ стабильности по подвыборкам

**Кросс-валидация производительности:**

```python
# 5-fold анализ стабильности
cv_results_autoencoder = {
    'f1_scores': [0.714, 0.721, 0.709, 0.725, 0.715],
    'mean': 0.717, 
    'std': 0.006,
    'cv': 0.008  # Коэффициент вариации
}

cv_results_lstm = {
    'f1_scores': [0.785, 0.791, 0.782, 0.794, 0.789],
    'mean': 0.788,
    'std': 0.005,
    'cv': 0.006  # Более стабильная модель
}
```

### Приложение Д. Технические конфигурации и параметры

#### Д.1 Конфигурация экспериментальной среды

**Системные требования:**
```yaml
system:
  os: "Ubuntu 20.04 LTS (WSL2)"
  python: "3.8.10"
  cuda: "11.6"
  gpu: "NVIDIA GeForce RTX 3080"
  ram: "32GB DDR4"
  storage: "1TB NVMe SSD"

dependencies:
  pytorch: "1.12.1+cu116"
  numpy: "1.24.3"
  pandas: "1.5.3"
  scikit-learn: "1.2.2"
  matplotlib: "3.7.1"
  seaborn: "0.12.2"
```

#### Д.2 Параметры моделей

**GRU-Автоэнкодер конфигурация:**
```yaml
autoencoder:
  architecture:
    vocab_size: 151
    embedding_dim: 64
    hidden_dim: 128
    num_layers: 2
    dropout: 0.2
    
  training:
    batch_size: 64
    learning_rate: 5e-05
    epochs: 15
    optimizer: "Adam"
    gradient_clip: 1.0
    
  early_stopping:
    patience: 8
    min_delta: 1e-4
    monitor: "val_loss"
    
  device: "cuda"
  deterministic: true
  seed: 42
```

**LSTM модель конфигурация:**
```yaml
lstm:
  architecture:
    vocab_size: 151
    hidden_dim: 384
    num_layers: 3
    dropout: 0.15
    
  training:
    batch_size: 32
    learning_rate: 3e-05
    epochs: 22
    optimizer: "Adam"
    gradient_clip: 1.0
    
  early_stopping:
    patience: 8
    min_delta: 1e-4
    monitor: "val_loss"
    
  device: "cuda"
  deterministic: true
  seed: 42
```

#### Д.3 Разделение данных и предобработка

**Стратегия разделения PLAID датасета:**
```yaml
data_split:
  strategy: "temporal_stratified"
  train: 
    percentage: 0.6
    type: "normal_only"  # Только нормальные данные
    size: 22,907  # 60% от 38,178
    
  validation:
    percentage: 0.2  
    type: "normal_only"
    size: 7,636   # 20% от 38,178
    
  test:
    percentage: 0.2
    type: "mixed"  # Нормальные + все атаки
    normal_size: 7,635   # 20% от 38,178
    attack_size: 1,145   # Все атаки
    total_size: 8,780
    
dataset_statistics:
  name: "PLAID"
  total_sequences: 39,323
  normal_sequences: 38,178 (97.09%)
  attack_sequences: 1,145 (2.91%)
  unique_syscalls: 151
  imbalance_ratio: "1:33.3"
  
preprocessing:
  encoding: "label_encoding"
  padding: "dynamic"
  sequence_length_filter: 
    min: 8
    max: 4495
  normalization: "none"  # Для категориальных данных
```

#### Д.4 Метрики и пороги оценки

**Система вычисления метрик:**
```yaml
metrics:
  primary:
    - accuracy
    - precision  
    - recall
    - f1_score
    - roc_auc
    - average_precision
    
  secondary:
    - specificity
    - npv  # Negative Predictive Value
    - mcc  # Matthews Correlation Coefficient
    - balanced_accuracy
    
  threshold_selection:
    method: "youden_index"  # max(TPR - FPR)
    alternative_methods:
      - "f1_optimal"
      - "precision_recall_balance"
      - "percentile_95"
      
  statistical_tests:
    mcnemar: true
    bootstrap_ci: 
      enabled: true
      n_iterations: 1000
      confidence_level: 0.95
```

#### Д.5 Экспериментальный pipeline

**Воспроизводимость экспериментов:**
```yaml
experiment_management:
  base_directory: "trials/"
  naming_convention: "{model_type}_{timestamp}"
  
  logging:
    level: "INFO"
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file: "{experiment_dir}/experiment.log"
    
  checkpointing:
    save_best: true
    save_last: true
    metric: "val_loss"
    mode: "min"
    
  artifacts:
    model_weights: "{experiment_dir}/{model_name}_best.pth"
    training_history: "{experiment_dir}/{model_name}_history.pkl" 
    test_results: "{experiment_dir}/{model_name}_results.pkl"
    config: "{experiment_dir}/config.yaml"
    plots: "{experiment_dir}/plots/"
    
reproducibility:
  torch_seed: 42
  numpy_seed: 42
  random_seed: 42
  cuda_deterministic: true
  benchmark: false
```

#### Д.6 Визуализация и отчетность

**Настройки графиков:**
```yaml
visualization:
  style: "seaborn-v0_8-whitegrid"
  palette: "Set2"
  dpi: 300
  format: "png"
  
  plot_types:
    roc_curve:
      figsize: [10, 8]
      title_size: 16
      label_size: 14
      legend_size: 12
      
    precision_recall:
      figsize: [10, 8] 
      baseline_style: "dashed"
      baseline_alpha: 0.6
      
    comprehensive_analysis:
      figsize: [16, 12]
      subplots: [2, 2]
      hspace: 0.3
      wspace: 0.3
      
    training_history:
      figsize: [15, 6]
      subplots: [1, 2]
      grid: true
      alpha: 0.3
      
  colors:
    normal_data: "#1f77b4"  # Синий
    attack_data: "#ff7f0e"  # Оранжевый  
    threshold: "#d62728"    # Красный
    optimal_point: "#2ca02c" # Зеленый
```

---