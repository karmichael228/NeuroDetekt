#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üß™ –ö–ª–∞—Å—Å—ã –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

–°–æ–¥–µ—Ä–∂–∏—Ç:
- Evaluator: –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
- LSTMEvaluator: –æ—Ü–µ–Ω–∫–∞ LSTM –º–æ–¥–µ–ª–µ–π
- AutoencoderEvaluator: –æ—Ü–µ–Ω–∫–∞ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–≤
"""

import time
from pathlib import Path

import numpy as np
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm

from ..models import LSTMModel
from ..utils.metrics import (
    calculate_metrics,
    evaluate_anomaly_detection,
    print_metrics_report,
)


class Evaluator:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π."""

    def __init__(self, model, device="cuda"):
        """
        Args:
            model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å PyTorch
            device (str): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        """
        self.model = model
        self.device = torch.device(
            device if torch.cuda.is_available() and device == "cuda" else "cpu"
        )
        self.model = self.model.to(self.device)
        self.model.eval()

        print(f"üß™ Evaluator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")

    def get_scores(self, dataloader):
        """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö. –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω."""
        raise NotImplementedError("–ú–µ—Ç–æ–¥ get_scores –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω")

    @classmethod
    def load_from_checkpoint(cls, checkpoint_path, model_class, model_params=None, device="cuda"):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ checkpoint."""
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        if model_params is None:
            model_params = {}

        model = model_class(**model_params)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)

        if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
            model.load_state_dict(checkpoint["model_state_dict"])
            print(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint —ç–ø–æ—Ö–∏ {checkpoint.get('epoch', 'N/A')}")
        else:
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —ç—Ç–æ state_dict
            model.load_state_dict(checkpoint)

        return cls(model, device)


class LSTMEvaluator(Evaluator):
    """–û—Ü–µ–Ω—â–∏–∫ –¥–ª—è LSTM –º–æ–¥–µ–ª–µ–π."""

    def __init__(self, model, device="cuda"):
        super().__init__(model, device)
        print("üß† LSTM Evaluator –≥–æ—Ç–æ–≤")

    def get_scores(self, dataloader, nll=True):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è LSTM –º–æ–¥–µ–ª–∏.

        Args:
            dataloader: DataLoader —Å –¥–∞–Ω–Ω—ã–º–∏
            nll (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å negative log likelihood –∫–∞–∫ –æ—Ü–µ–Ω–∫—É

        Returns:
            np.array: –û—Ü–µ–Ω–∫–∏ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        self.model.eval()
        all_scores = []

        with torch.no_grad():
            pbar = tqdm(dataloader, desc="üìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫", colour="blue")

            for batch in pbar:
                batch = batch.to(self.device)

                # –î–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –±–∞—Ç—á–µ
                for i in range(len(batch)):
                    sequence = batch[i]

                    # –£–±–∏—Ä–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç –¥–ª—è input –∏ –ø–µ—Ä–≤—ã–π –¥–ª—è target
                    input_seq = sequence[:-1].unsqueeze(0)  # [1, seq_len-1]
                    target_seq = sequence[1:]  # [seq_len-1]

                    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    output = self.model(input_seq)  # [1, seq_len-1, vocab_size]
                    output = output.squeeze(0)  # [seq_len-1, vocab_size]

                    # –ù–∞—Ö–æ–¥–∏–º –≤–∞–ª–∏–¥–Ω—ã–µ (–Ω–µ padding) –ø–æ–∑–∏—Ü–∏–∏
                    valid_mask = target_seq != 0

                    if valid_mask.sum() == 0:
                        # –ï—Å–ª–∏ –≤—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å - padding
                        all_scores.append(0.0)
                        continue

                    # –§–∏–ª—å—Ç—Ä—É–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏
                    valid_output = output[valid_mask]  # [valid_len, vocab_size]
                    valid_target = target_seq[valid_mask]  # [valid_len]

                    # –í—ã—á–∏—Å–ª—è–µ–º negative log-likelihood
                    loss = torch.nn.functional.nll_loss(
                        valid_output, valid_target, reduction="mean"
                    )

                    all_scores.append(loss.item())

                pbar.set_postfix({"–æ–±—Ä–∞–∑—Ü–æ–≤": len(all_scores)})

        scores_array = np.array(all_scores)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫–∏
        if len(scores_array) > 0:
            # –û—Ç—Å–µ–∫–∞–µ–º –≤—ã–±—Ä–æ—Å—ã
            upper_bound = np.percentile(scores_array, 99.9)
            scores_array = np.clip(scores_array, 0, upper_bound)

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 1] –µ—Å–ª–∏ nll=False
            if not nll:
                if scores_array.max() > scores_array.min():
                    scores_array = (scores_array - scores_array.min()) / (
                        scores_array.max() - scores_array.min()
                    )

        return scores_array

    def evaluate_anomaly_detection(
        self, normal_loader, attack_loader, threshold_method="percentile", threshold_value=95
    ):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π LSTM –º–æ–¥–µ–ª–∏.

        Args:
            normal_loader: DataLoader —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            attack_loader: DataLoader —Å –¥–∞–Ω–Ω—ã–º–∏ –∞—Ç–∞–∫
            threshold_method (str): –ú–µ—Ç–æ–¥ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ä–æ–≥–∞ ('percentile', 'optimal')
            threshold_value: –ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ä–æ–≥–∞

        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
        """
        print(f"üß™ –û—Ü–µ–Ω–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π LSTM –º–æ–¥–µ–ª–∏...")

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("üìä –û—Ü–µ–Ω–∫–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        normal_scores = self.get_scores(normal_loader)

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –∞—Ç–∞–∫
        print("üî¥ –û—Ü–µ–Ω–∫–∞ –∞—Ç–∞–∫...")
        attack_scores = self.get_scores(attack_loader)

        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä–æ–≥
        if threshold_method == "percentile":
            threshold = np.percentile(normal_scores, threshold_value)
        else:
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã
            threshold = np.percentile(normal_scores, threshold_value)

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        evaluation = evaluate_anomaly_detection(normal_scores, attack_scores, threshold_value)

        print_metrics_report(evaluation, "LSTM –¥–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π")

        return {
            "normal_scores": normal_scores,
            "attack_scores": attack_scores,
            "threshold": threshold,
            "evaluation": evaluation,
        }


class AutoencoderEvaluator(Evaluator):
    """–û—Ü–µ–Ω—â–∏–∫ –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–≤."""

    def __init__(self, model, device="cuda"):
        super().__init__(model, device)
        print("ü§ñ Autoencoder Evaluator –≥–æ—Ç–æ–≤")

    def get_reconstruction_errors(self, dataloader):
        """
        –ü–æ–ª—É—á–∞–µ—Ç –æ—à–∏–±–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞.

        Args:
            dataloader: DataLoader —Å –¥–∞–Ω–Ω—ã–º–∏

        Returns:
            np.array: –û—à–∏–±–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        self.model.eval()
        all_errors = []

        with torch.no_grad():
            pbar = tqdm(dataloader, desc="üìä –û—à–∏–±–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏", colour="purple")

            for batch_x in pbar:
                batch_x = batch_x.to(self.device)
                errors = self.model.get_reconstruction_error(batch_x)
                all_errors.extend(errors.cpu().numpy())

                pbar.set_postfix({"–æ–±—Ä–∞–∑—Ü–æ–≤": len(all_errors)})

        return np.array(all_errors)

    def evaluate_anomaly_detection(self, normal_loader, attack_loader, threshold_percentile=95):
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞.

        Args:
            normal_loader: DataLoader —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            attack_loader: DataLoader —Å –¥–∞–Ω–Ω—ã–º–∏ –∞—Ç–∞–∫
            threshold_percentile (int): –ü–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–æ—Ä–æ–≥–∞

        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
        """
        print(f"üß™ –û—Ü–µ–Ω–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞...")

        # –ü–æ–ª—É—á–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("üìä –û—à–∏–±–∫–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        normal_errors = self.get_reconstruction_errors(normal_loader)

        # –ü–æ–ª—É—á–∞–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –∞—Ç–∞–∫
        print("üî¥ –û—à–∏–±–∫–∏ –∞—Ç–∞–∫...")
        attack_errors = self.get_reconstruction_errors(attack_loader)

        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        evaluation = evaluate_anomaly_detection(normal_errors, attack_errors, threshold_percentile)

        print_metrics_report(evaluation, "–ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–µ—Ç–µ–∫—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π")

        return {
            "normal_errors": normal_errors,
            "attack_errors": attack_errors,
            "evaluation": evaluation,
        }

    def test_with_mixed_data(self, test_loader, test_labels, threshold):
        """
        –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ —Å–º–µ—à–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

        Args:
            test_loader: DataLoader —Å–æ —Å–º–µ—à–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            test_labels: –ú–µ—Ç–∫–∏ (0=–Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ, 1=–∞—Ç–∞–∫–∏)
            threshold (float): –ü–æ—Ä–æ–≥ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–º–µ—à–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

        # –ü–æ–ª—É—á–∞–µ–º –æ—à–∏–±–∫–∏
        errors = self.get_reconstruction_errors(test_loader)

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = (errors > threshold).astype(int)

        # –ú–µ—Ç—Ä–∏–∫–∏
        test_labels_np = test_labels.numpy() if hasattr(test_labels, "numpy") else test_labels
        metrics = calculate_metrics(test_labels_np, predictions, errors)

        print_metrics_report(metrics, "–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Å–º–µ—à–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

        return {
            "errors": errors,
            "predictions": predictions,
            "labels": test_labels_np,
            "threshold": threshold,
            "metrics": metrics,
        }


def load_and_evaluate_lstm(checkpoint_path, test_data, vocab_size=229, device="cuda"):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç LSTM –º–æ–¥–µ–ª—å.

    Args:
        checkpoint_path (str): –ü—É—Ç—å –∫ checkpoint
        test_data: –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        vocab_size (int): –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è
        device (str): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ

    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏
    """
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    evaluator = LSTMEvaluator.load_from_checkpoint(
        checkpoint_path, LSTMModel, {"vocab_size": vocab_size}, device
    )

    # –û—Ü–µ–Ω–∫–∞ –±—É–¥–µ—Ç –∑–∞–≤–∏—Å–µ—Ç—å –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞ test_data
    # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    return evaluator


def save_evaluation_results(results, output_path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏."""
    import pickle

    with open(output_path, "wb") as f:
        pickle.dump(results, f)
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
