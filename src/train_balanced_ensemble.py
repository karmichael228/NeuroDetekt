#!/usr/bin/env python3
# -*- coding: utf-8 -*

"""
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è LSTM –º–æ–¥–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö
    –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è IDS.
"""

import argparse
import time
import os
import random
import sys
import warnings
from datetime import datetime
from pathlib import Path

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ NumPy –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º torch
try:
    import numpy as np
    numpy_version = np.__version__
    major_version = int(numpy_version.split('.')[0])
    if major_version >= 2:
        print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –≤–µ—Ä—Å–∏—è NumPy {numpy_version}. PyTorch –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å NumPy 2.x.")
        print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å NumPy 1.x –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PyTorch.")
        print("   –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å: conda install numpy=1.24.3")
        sys.exit(1)
except ImportError:
    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å NumPy. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–∫–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    sys.exit(1)

try:
    import torch
    import matplotlib
    matplotlib.use('Agg')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ç–∫–µ–Ω–¥ –±–µ–∑ GUI
    import matplotlib.pyplot as plt
    from torch.nn import functional as F
    from torch.optim import Adam, lr_scheduler
    from tqdm import tqdm
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve
except ImportError as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
    sys.exit(1)

try:
    from data_processing import get_data, load_data_splits, SequencePairDataset, SequenceDataset, collate_fn, test_collate_fn
    from models import create_lstm_model, LSTMModel
    from training_utils import TimeTracker, LossTracker, validate_model
except ImportError as e:
    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥—É–ª–µ–π: {e}")
    print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –Ω–∞—Ö–æ–¥–∏—Ç–µ—Å—å –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞.")
    sys.exit(1)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
SEED = 42
np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

# –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore", category=UserWarning, message="Failed to initialize NumPy")


def create_parser():
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description=f"–û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è LSTM –º–æ–¥–µ–ª–µ–π —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –¥–∞–Ω–Ω—ã—Ö.",
    )
    parser.add_argument(
        "--batch_size",
        default=96,
        type=int,
        help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.",
    )
    parser.add_argument(
        "--epochs", 
        default=15, 
        type=int, 
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è."
    )
    parser.add_argument(
        "--early_stopping",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–Ω–Ω—é—é –æ—Å—Ç–∞–Ω–æ–≤–∫—É –æ–±—É—á–µ–Ω–∏—è.",
    )
    parser.add_argument(
        "--cells",
        default=128,
        type=int,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —è—á–µ–µ–∫ –≤ LSTM —Å–ª–æ—è—Ö.",
    )
    parser.add_argument(
        "--depth",
        default=2,
        type=int,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ LSTM.",
    )
    parser.add_argument(
        "--dropout",
        default=0.25,
        type=float,
        help="–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç dropout.",
    )
    parser.add_argument(
        "--patience",
        default=5,
        type=int,
        help="–¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è.",
    )
    parser.add_argument(
        "--device",
        default="cuda",
        choices=["cuda", "cpu"],
        help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (cuda –∏–ª–∏ cpu).",
    )
    parser.add_argument(
        "--num_workers",
        default=4,
        type=int,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.",
    )
    parser.add_argument(
        "--learning_rate",
        default=1e-3,
        type=float,
        help="–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è.",
    )
    parser.add_argument(
        "--ensemble_size",
        default=3,
        type=int,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ.",
    )
    parser.add_argument(
        "--balance_factor",
        default=1.5,
        type=float,
        help="–§–∞–∫—Ç–æ—Ä –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–ª—è —à—Ç—Ä–∞—Ñ–∞ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π.",
    )
    parser.add_argument(
        "--output_dir",
        default="trials/lstm_plaid_improved",
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.",
    )

    return parser


def get_device(device_arg):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (CUDA –∏–ª–∏ CPU)."""
    try:
        if device_arg == "cuda" and torch.cuda.is_available():
            device = torch.device("cuda")
            gpu_name = torch.cuda.get_device_name(0)
            memory_allocated = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º GPU: {gpu_name}")
            print(f"üìä –î–æ—Å—Ç—É–ø–Ω–∞—è –ø–∞–º—è—Ç—å GPU: {memory_allocated:.2f} GB")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ CUDA
            cuda_version = torch.version.cuda
            if cuda_version:
                print(f"üîß –í–µ—Ä—Å–∏—è CUDA: {cuda_version}")
            
            return device
        else:
            if device_arg == "cuda":
                print("‚ö†Ô∏è CUDA –∑–∞–ø—Ä–æ—à–µ–Ω–∞, –Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –≤–º–µ—Å—Ç–æ GPU.")
            else:
                print("üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU")
            return torch.device("cpu")
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞: {e}")
        print("üíª –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –∫–∞–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç")
        return torch.device("cpu")


def create_balanced_dataset(train_data, ratio=1.0, duplicate_factor=1):
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç, –¥—É–±–ª–∏—Ä—É—è –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    
    Args:
        train_data: –°–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        ratio: –ñ–µ–ª–∞–µ–º–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ (–¥–ª–∏–Ω–Ω—ã–µ / –∫–æ—Ä–æ—Ç–∫–∏–µ)
        duplicate_factor: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
        
    Returns:
        –°–ø–∏—Å–æ–∫ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
    """
    # –ù–∞—Ö–æ–¥–∏–º –º–µ–¥–∏–∞–Ω–Ω—É—é –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    seq_lengths = [len(seq) for seq in train_data]
    median_length = np.median(seq_lengths)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –¥–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    short_seqs = [seq for seq in train_data if len(seq) < median_length]
    long_seqs = [seq for seq in train_data if len(seq) >= median_length]
    
    print(f"–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:")
    print(f"  –í—Å–µ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(train_data)}")
    print(f"  –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {len(short_seqs)}")
    print(f"  –î–ª–∏–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {len(long_seqs)}")
    print(f"  –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ (–¥–ª–∏–Ω–Ω—ã–µ/–∫–æ—Ä–æ—Ç–∫–∏–µ): {len(long_seqs)/max(1, len(short_seqs)):.2f}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    target_short_count = int(len(long_seqs) / ratio)
    if len(short_seqs) < target_short_count:
        additional_needed = target_short_count - len(short_seqs)
        
        # –î—É–±–ª–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        duplicated_short = []
        for _ in range(duplicate_factor):
            if len(duplicated_short) >= additional_needed:
                break
            duplicated_short.extend(random.sample(short_seqs, min(additional_needed, len(short_seqs))))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        balanced_data = long_seqs + short_seqs + duplicated_short[:additional_needed]
    else:
        # –ï—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, –ø—Ä–æ—Å—Ç–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
        balanced_data = long_seqs + short_seqs
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    random.shuffle(balanced_data)
    
    print(f"–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:")
    print(f"  –í—Å–µ–≥–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {len(balanced_data)}")
    seq_lengths = [len(seq) for seq in balanced_data]
    print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {np.mean(seq_lengths):.2f}")
    print(f"  –ú–µ–¥–∏–∞–Ω–∞ –¥–ª–∏–Ω—ã: {np.median(seq_lengths):.2f}")
    
    return balanced_data


def train_epoch(model, train_loader, optimizer, criterion, device, epoch, scheduler=None):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É —ç–ø–æ—Ö—É –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."""
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    epoch_start = time.time()
    
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∫—ç—à CUDA –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    progress_bar = tqdm(train_loader, desc=f"üîÑ –≠–ø–æ—Ö–∞ {epoch}", 
                        bar_format="{l_bar}{bar:30}{r_bar}", 
                        ncols=100)
    
    for batch_idx, (inputs, targets) in enumerate(progress_bar):
        inputs, targets = inputs.to(device), targets.to(device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–µ–ª–∏ –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª–∏–Ω–Ω—ã—Ö —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª
        targets = targets.view(-1)
        outputs = outputs.view(-1, outputs.size(2))
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è padding
        non_pad_mask = (targets != 0)
        if non_pad_mask.sum() > 0:
            outputs = outputs[non_pad_mask]
            targets = targets[non_pad_mask]
            
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * inputs.size(0)
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            progress_bar.set_postfix({
                "‚ùå –ø–æ—Ç–µ—Ä—è": f"{loss.item():.4f}", 
                "‚úÖ —Ç–æ—á–Ω–æ—Å—Ç—å": f"{100.0 * correct / total:.2f}%",
                "‚è±Ô∏è –≤—Ä–µ–º—è": f"{time.time() - epoch_start:.1f}s"
            })
            
            # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π
            if batch_idx % 50 == 0 and batch_idx > 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
    
    # –®–∞–≥ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –¥–µ–ª–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ —ç–ø–æ—Ö–∏, –µ—Å–ª–∏ –æ–Ω –Ω–µ –Ω—É–∂–¥–∞–µ—Ç—Å—è –≤ –º–µ—Ç—Ä–∏–∫–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    if scheduler is not None and not isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):
        scheduler.step()
    
    epoch_loss = running_loss / total if total > 0 else 0
    epoch_acc = correct / total if total > 0 else 0
    
    epoch_time = time.time() - epoch_start
    print(f"\nüìà –ò—Ç–æ–≥–∏ —ç–ø–æ—Ö–∏ {epoch}:")
    print(f"   ‚ùå –ü–æ—Ç–µ—Ä—è: {epoch_loss:.4f}, ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å: {epoch_acc:.4f}")
    print(f"   ‚è±Ô∏è –í—Ä–µ–º—è —ç–ø–æ—Ö–∏: {epoch_time:.2f}s\n")
    
    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∫—ç—à CUDA –ø–æ—Å–ª–µ —ç–ø–æ—Ö–∏
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    return epoch_loss, epoch_acc, epoch_time


def validate_epoch(model, val_loader, criterion, device, epoch):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –º–æ–¥–µ–ª–∏."""
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    progress_bar = tqdm(val_loader, desc=f"üîç –í–∞–ª–∏–¥–∞—Ü–∏—è —ç–ø–æ—Ö–∞ {epoch}", 
                       bar_format="{l_bar}{bar:30}{r_bar}", 
                       ncols=100)
    
    with torch.no_grad():
        for inputs, targets in progress_bar:
            inputs, targets = inputs.to(device), targets.to(device)
            
            outputs = model(inputs)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ü–µ–ª–∏ –≤ —Ç–µ–Ω–∑–æ—Ä –¥–ª–∏–Ω–Ω—ã—Ö —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª
            targets = targets.view(-1)
            outputs = outputs.view(-1, outputs.size(2))
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∞—Å–∫—É –¥–ª—è –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è padding
            non_pad_mask = (targets != 0)
            if non_pad_mask.sum() > 0:
                outputs = outputs[non_pad_mask]
                targets = targets[non_pad_mask]
                
                loss = criterion(outputs, targets)
                
                running_loss += loss.item() * inputs.size(0)
                
                # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
                _, predicted = outputs.max(1)
                total += targets.size(0)
                correct += predicted.eq(targets).sum().item()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                progress_bar.set_postfix({
                    "‚ùå –ø–æ—Ç–µ—Ä—è": f"{loss.item():.4f}", 
                    "‚úÖ —Ç–æ—á–Ω–æ—Å—Ç—å": f"{100.0 * correct / total:.2f}%"
                })
    
    epoch_loss = running_loss / total if total > 0 else 0
    epoch_acc = correct / total if total > 0 else 0
    
    print(f"üìä –í–∞–ª–∏–¥–∞—Ü–∏—è: ‚ùå –ü–æ—Ç–µ—Ä—è: {epoch_loss:.4f}, ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å: {epoch_acc:.4f}")
    
    return epoch_loss, epoch_acc


def find_optimal_threshold(scores, labels, balance_factor=1.0):
    """–ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ Precision/Recall.
    
    Args:
        scores (numpy.ndarray): –û—Ü–µ–Ω–∫–∏ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏
        labels (numpy.ndarray): –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (0: –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ, 1: –∞—Ç–∞–∫–∏)
        balance_factor (float): –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è —à—Ç—Ä–∞—Ñ–∞ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        
    Returns:
        float: –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
        dict: –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    """
    # –í—ã—á–∏—Å–ª—è–µ–º –∫—Ä–∏–≤—É—é Precision-Recall
    precision, recall, thresholds = precision_recall_curve(labels, scores)
    
    # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
    precision = np.maximum(precision, 1e-10)
    recall = np.maximum(recall, 1e-10)
    
    # –í—ã—á–∏—Å–ª—è–µ–º F-–±–µ—Ç–∞ –º–µ—Ä—É —Å —É—á–µ—Ç–æ–º balance_factor
    # balance_factor > 1 –ø—Ä–∏–¥–∞–µ—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å precision (–º–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)
    # balance_factor < 1 –ø—Ä–∏–¥–∞–µ—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å recall (–º–µ–Ω—å—à–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∞—Ç–∞–∫)
    beta_squared = 1 / (balance_factor ** 2)
    f_scores = (1 + beta_squared) * (precision * recall) / (beta_squared * precision + recall)
    
    # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å
    optimal_idx = np.argmax(f_scores[:-1])  # –∏—Å–∫–ª—é—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —ç–ª–µ–º–µ–Ω—Ç (—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–æ—Ä–æ–≥—É -inf)
    optimal_threshold = thresholds[optimal_idx] if len(thresholds) > 0 else 0.5
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞
    predictions = (scores >= optimal_threshold).astype(int)
    metrics = {
        'threshold': optimal_threshold,
        'accuracy': accuracy_score(labels, predictions),
        'precision': precision_score(labels, predictions),
        'recall': recall_score(labels, predictions),
        'f1_score': f1_score(labels, predictions),
        'f_beta': f_scores[optimal_idx] if len(f_scores) > 0 else 0.0
    }
    
    return optimal_threshold, metrics


def get_ensemble_scores(models, dataloader, device):
    """–ü–æ–ª—É—á–∞–µ—Ç —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –æ—Ç –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π.
    
    Args:
        models (list): –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π LSTM
        dataloader (DataLoader): –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
        device (str): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        
    Returns:
        numpy.ndarray: –ú–∞—Å—Å–∏–≤ —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã—Ö –æ—Ü–µ–Ω–æ–∫ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏
    """
    all_scores = []
    
    # –ü–æ–ª—É—á–∞–µ–º –æ—Ü–µ–Ω–∫–∏ –æ—Ç –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    for model_idx, model in enumerate(models):
        model.eval()
        model_scores = []
        
        with torch.no_grad():
            for sequences in tqdm(dataloader, desc=f"–ú–æ–¥–µ–ª—å {model_idx+1}/{len(models)}"):
                sequences = sequences.to(device)
                batch_size = sequences.size(0)
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                outputs = model(sequences[:, :-1])
                targets = sequences[:, 1:]
                
                # –í—ã—á–∏—Å–ª—è–µ–º loss –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω–æ
                batch_scores = []
                for i in range(batch_size):
                    output = outputs[i].view(-1, outputs.size(-1))
                    target = targets[i].view(-1)
                    
                    # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º padding
                    mask = (target != 0)
                    if mask.sum() > 0:
                        output = output[mask]
                        target = target[mask]
                        
                        loss = torch.nn.functional.nll_loss(output, target, reduction='mean')
                        batch_scores.append(loss.item())
                    else:
                        # –ï—Å–ª–∏ –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã padding, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Å–æ–∫—É—é –æ—Ü–µ–Ω–∫—É
                        batch_scores.append(10.0)
                
                model_scores.extend(batch_scores)
        
        all_scores.append(model_scores)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤ –∏ –≤—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ
    all_scores = np.array(all_scores)
    avg_scores = np.mean(all_scores, axis=0)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫–∏ [0, 1]
    if len(avg_scores) > 0 and max(avg_scores) > min(avg_scores):
        avg_scores = (avg_scores - min(avg_scores)) / (max(avg_scores) - min(avg_scores))
    
    return avg_scores


def create_safe_dataloader(dataset, batch_size, shuffle, collate_fn, num_workers, device, is_test=False):
    """–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫.
    
    Args:
        dataset: –ù–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        shuffle: –§–ª–∞–≥ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        collate_fn: –§—É–Ω–∫—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        num_workers: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        is_test: –§–ª–∞–≥ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
        
    Returns:
        DataLoader: –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    """
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
    use_multiprocessing = num_workers > 0
    
    try:
        if use_multiprocessing:
            # –ü–æ–ø—ã—Ç–∫–∞ —Å–æ–∑–¥–∞—Ç—å –∑–∞–≥—Ä—É–∑—á–∏–∫ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ä–∞–±–æ—á–∏–º–∏
            return torch.utils.data.DataLoader(
                dataset,
                batch_size=batch_size,
                shuffle=shuffle,
                collate_fn=collate_fn if not is_test else test_collate_fn,
                num_workers=num_workers,
                pin_memory=(str(device) == 'cuda')
            )
    except RuntimeError as e:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∞, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–æ–º, –æ—Ç–∫–ª—é—á–∞–µ–º –µ–≥–æ
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å {num_workers} —Ä–∞–±–æ—á–∏–º–∏: {e}")
        print("   –û—Ç–∫–ª—é—á–∞–µ–º –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö.")
        
    # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - –æ–¥–Ω–æ–ø—Ä–æ—Ü–µ—Å—Å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫
    return torch.utils.data.DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        collate_fn=collate_fn if not is_test else test_collate_fn,
        num_workers=0,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º 0 –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –æ—à–∏–±–æ–∫ –º—É–ª—å—Ç–∏–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
        pin_memory=(str(device) == 'cuda')
    )


def main(
    batch_size=96,
    epochs=15,
    early_stopping=True,
    cells=128,
    depth=2,
    dropout=0.25,
    patience=5,
    device="cuda",
    num_workers=4,
    learning_rate=1e-3,
    ensemble_size=3,
    balance_factor=1.5,
    output_dir="trials/lstm_plaid_improved"
):
    """–í—Ö–æ–¥–Ω–∞—è —Ç–æ—á–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π."""
    start_time = time.time()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    device = get_device(device)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True, parents=True)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        train_data, _, test_val, atk = load_data_splits(
            "plaid", train_pct=1.0, ratio=1.0
        )
        
        # –°–æ–∑–¥–∞–µ–º –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        balanced_train_data = create_balanced_dataset(train_data, ratio=1.0, duplicate_factor=2)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –º–µ—Ç–∫–∏
        test_data = test_val + atk
        test_labels = torch.zeros(len(test_val) + len(atk))
        test_labels[len(test_val):] = 1
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫
        test_dataset = SequenceDataset(test_data)
        test_loader = create_safe_dataloader(
            test_dataset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=test_collate_fn,
            num_workers=num_workers,
            device=device,
            is_test=True
        )
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        model_args = {
            'vocab_size': 229,  # –î–ª—è PLAID –¥–∞—Ç–∞—Å–µ—Ç–∞
            'cells': cells,
            'depth': depth,
            'dropout': dropout,
        }
        
        # –û–±—É—á–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π
        ensemble_models = []
        for i in range(ensemble_size):
            print(f"\n{'='*50}")
            print(f"üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {i+1}/{ensemble_size}")
            print(f"{'='*50}")
            
            # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏
            # –ú–µ–Ω—è–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            if i > 0:
                # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
                random.shuffle(balanced_train_data)
            
            train_dataset = SequencePairDataset(balanced_train_data)
            train_loader = create_safe_dataloader(
                train_dataset,
                batch_size=batch_size,
                shuffle=True,
                collate_fn=collate_fn,
                num_workers=num_workers,
                device=device
            )
            
            # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
            model, optimizer, criterion = create_lstm_model(
                vocab_size=model_args['vocab_size'],
                cells=model_args['cells'],
                depth=model_args['depth'],
                dropout=model_args['dropout'],
                device=device,
                learning_rate=learning_rate
            )
            
            # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è
            scheduler = lr_scheduler.StepLR(
                optimizer, step_size=3, gamma=0.5
            )
            
            # –î–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            best_train_loss = float("inf")
            best_model_state = None
            patience_counter = 0
            
            # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
            train_losses = []
            train_accs = []
            
            # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
            for epoch in range(1, epochs + 1):
                # –û–±—É—á–µ–Ω–∏–µ
                try:
                    train_loss, train_acc, epoch_time = train_epoch(
                        model, train_loader, optimizer, criterion, device, epoch, scheduler
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    train_losses.append(train_loss)
                    train_accs.append(train_acc)
                    
                    # –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –ø–æ—Ç–µ—Ä–∏
                    if early_stopping:
                        if train_loss < best_train_loss:
                            best_train_loss = train_loss
                            best_model_state = model.state_dict().copy()
                            patience_counter = 0
                        else:
                            patience_counter += 1
                            if patience_counter >= patience:
                                print(f"‚ö†Ô∏è –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch}")
                                break
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —ç–ø–æ—Ö–∏ {epoch}: {e}")
                    print("   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É —ç–ø–æ—Ö—É –∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º.")
                    continue
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –±—ã–ª–∞ —Ä–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞
            if early_stopping and best_model_state is not None:
                model.load_state_dict(best_model_state)
            
            # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏
            try:
                plt.figure(figsize=(12, 5))
                epochs_range = range(1, len(train_losses) + 1)
                
                plt.subplot(1, 2, 1)
                plt.plot(epochs_range, train_losses, 'b-', label='–ü–æ—Ç–µ—Ä—è –æ–±—É—á–µ–Ω–∏—è')
                plt.title(f'–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –º–æ–¥–µ–ª–∏ {i+1}')
                plt.xlabel('–≠–ø–æ—Ö–∏')
                plt.ylabel('–ü–æ—Ç–µ—Ä—è')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                
                plt.subplot(1, 2, 2)
                plt.plot(epochs_range, train_accs, 'b-', label='–¢–æ—á–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
                plt.title(f'–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ {i+1}')
                plt.xlabel('–≠–ø–æ—Ö–∏')
                plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
                plt.legend()
                plt.grid(True, linestyle='--', alpha=0.7)
                
                plt.tight_layout()
                plt.savefig(output_path / f"model_{i+1}_training.png")
                plt.close()
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            model_path = output_path / f"model_{i+1}.pt"
            torch.save(model, model_path)
            print(f"üíæ –ú–æ–¥–µ–ª—å {i+1} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –≤ –∞–Ω—Å–∞–º–±–ª—å
            ensemble_models.append(model)
            
            # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ CUDA
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ
        print("\n" + "="*50)
        print(f"üìä –û—Ü–µ–Ω–∫–∞ –∞–Ω—Å–∞–º–±–ª—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ")
        print("="*50)
        
        # –ü–æ–ª—É—á–∞–µ–º —É—Å—Ä–µ–¥–Ω–µ–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –æ—Ç –∞–Ω—Å–∞–º–±–ª—è
        try:
            ensemble_scores = get_ensemble_scores(ensemble_models, test_loader, device)
            
            # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
            threshold, metrics = find_optimal_threshold(ensemble_scores, test_labels, balance_factor)
            
            # –í—ã–≤–æ–¥–∏–º –º–µ—Ç—Ä–∏–∫–∏
            print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω—Å–∞–º–±–ª—è —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º {threshold:.4f}:")
            print(f"   ‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å: {metrics['accuracy']:.4f}")
            print(f"   üìè Precision: {metrics['precision']:.4f}")
            print(f"   üìè Recall: {metrics['recall']:.4f}")
            print(f"   üìè F1-–º–µ—Ä–∞: {metrics['f1_score']:.4f}")
            print(f"   üìè F-–±–µ—Ç–∞ (—Å balance_factor={balance_factor}): {metrics['f_beta']:.4f}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            with open(output_path / "ensemble_results.txt", "w") as f:
                f.write(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {threshold:.4f}\n")
                f.write(f"–¢–æ—á–Ω–æ—Å—Ç—å: {metrics['accuracy']:.4f}\n")
                f.write(f"Precision: {metrics['precision']:.4f}\n")
                f.write(f"Recall: {metrics['recall']:.4f}\n")
                f.write(f"F1-–º–µ—Ä–∞: {metrics['f1_score']:.4f}\n")
                f.write(f"F-–±–µ—Ç–∞ (—Å balance_factor={balance_factor}): {metrics['f_beta']:.4f}\n")
            
            # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—Ü–µ–Ω–æ–∫
            plt.figure(figsize=(10, 6))
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –æ—Ü–µ–Ω–∫–∏ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ –∏ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ
            normal_scores = ensemble_scores[test_labels == 0]
            attack_scores = ensemble_scores[test_labels == 1]
            
            # –°—Ç—Ä–æ–∏–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
            plt.hist(normal_scores, bins=50, alpha=0.5, label='–ù–æ—Ä–º–∞–ª—å–Ω—ã–µ', color='green')
            plt.hist(attack_scores, bins=50, alpha=0.5, label='–ê—Ç–∞–∫–∏', color='red')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é –ø–æ—Ä–æ–≥–∞
            plt.axvline(x=threshold, color='black', linestyle='--', 
                       label=f'–ü–æ—Ä–æ–≥ = {threshold:.3f}')
            
            plt.xlabel('–û—Ü–µ–Ω–∫–∞ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏')
            plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π')
            plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫ –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏ –∞–Ω—Å–∞–º–±–ª—è')
            plt.legend()
            plt.grid(True, linestyle='--', alpha=0.7)
            
            plt.tight_layout()
            plt.savefig(output_path / 'ensemble_score_distribution.png')
            plt.close()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ –∞–Ω—Å–∞–º–±–ª—è: {e}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        total_time = time.time() - start_time
        hours, remainder = divmod(total_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        print(f"\n‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {int(hours)}—á {int(minutes)}–º {int(seconds)}—Å")
        print(f"üíæ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {output_path}")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    parser = create_parser()
    args = parser.parse_args()
    sys.exit(main(**vars(args))) 