#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üéØ –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è LSTM + –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
"""

import numpy as np
import torch
import pickle
from pathlib import Path
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from src.main import NeuroDetekt
from src.models.lstm_model import LSTMModel
from src.models.gru_autoencoder import GRUAutoEncoder
from src.utils.data_processing import get_data

class EnsembleModel:
    """–ê–Ω—Å–∞–º–±–ª—å LSTM + –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –∞–Ω–æ–º–∞–ª–∏–π."""
    
    def __init__(self, lstm_path, autoencoder_path, device="cuda"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è.
        
        Args:
            lstm_path (str): –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π LSTM –º–æ–¥–µ–ª–∏
            autoencoder_path (str): –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–º—É –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä—É
            device (str): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        """
        self.device = torch.device(device if torch.cuda.is_available() else "cpu")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º LSTM –º–æ–¥–µ–ª—å
        self.lstm_model = self._load_lstm_model(lstm_path)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä
        self.autoencoder_model = self._load_autoencoder_model(autoencoder_path)
        
        print(f"üéØ –ê–Ω—Å–∞–º–±–ª—å —Å–æ–∑–¥–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
        print(f"   üß† LSTM –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        print(f"   ü§ñ –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
    
    def _load_lstm_model(self, model_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é LSTM –º–æ–¥–µ–ª—å."""
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ final_model
        model = LSTMModel(
            vocab_size=229,
            embedding_dim=384,  # –ö–∞–∫ –≤ final_model (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ –∏–∑ checkpoint)
            hidden_size=384,    # –ö–∞–∫ –≤ final_model
            num_layers=3,       # –ö–∞–∫ –≤ final_model
            dropout=0.15        # –ö–∞–∫ –≤ final_model
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=True)
        model.load_state_dict(checkpoint)
        model = model.to(self.device)
        model.eval()
        
        return model
    
    def _load_autoencoder_model(self, model_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã–π –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä."""
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞
        model = GRUAutoEncoder(
            vocab_size=229,
            embedding_dim=128,
            hidden_size=128,
            num_layers=2,
            latent_dim=64,
            dropout=0.2
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(self.device)
        model.eval()
        
        return model
    
    def get_lstm_scores(self, dataloader):
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–Ω–æ–º–∞–ª–∏–∏-—Å–∫–æ—Ä—ã –æ—Ç LSTM –º–æ–¥–µ–ª–∏."""
        self.lstm_model.eval()
        scores = []
        
        with torch.no_grad():
            for batch in dataloader:
                if isinstance(batch, tuple):
                    batch_x, _ = batch
                else:
                    batch_x = batch
                
                batch_x = batch_x.to(self.device)
                
                # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é –∫–∞–∫ –º–µ—Ä—É –∞–Ω–æ–º–∞–ª—å–Ω–æ—Å—Ç–∏
                inputs = batch_x[:, :-1]
                targets = batch_x[:, 1:]
                
                outputs = self.lstm_model(inputs)
                
                # –í—ã—á–∏—Å–ª—è–µ–º cross-entropy –¥–ª—è –∫–∞–∂–¥–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                batch_scores = []
                for seq_outputs, seq_targets in zip(outputs, targets):
                    seq_loss = torch.nn.functional.cross_entropy(
                        seq_outputs.view(-1, seq_outputs.size(-1)),
                        seq_targets.view(-1),
                        reduction='mean'
                    )
                    batch_scores.append(seq_loss.item())
                
                scores.extend(batch_scores)
        
        return np.array(scores)
    
    def get_autoencoder_scores(self, dataloader):
        """–ü–æ–ª—É—á–∞–µ—Ç –∞–Ω–æ–º–∞–ª–∏–∏-—Å–∫–æ—Ä—ã –æ—Ç –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞."""
        self.autoencoder_model.eval()
        scores = []
        
        with torch.no_grad():
            for batch in dataloader:
                if isinstance(batch, tuple):
                    batch_x, _ = batch
                else:
                    batch_x = batch
                
                batch_x = batch_x.to(self.device)
                errors = self.autoencoder_model.get_reconstruction_error(batch_x)
                scores.extend(errors.cpu().numpy())
        
        return np.array(scores)
    
    def predict_ensemble(self, test_loader, test_labels, strategy="weighted_voting", weights=None):
        """
        –î–µ–ª–∞–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –∞–Ω—Å–∞–º–±–ª—è.
        
        Args:
            test_loader: DataLoader —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            test_labels: –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
            strategy (str): –°—Ç—Ä–∞—Ç–µ–≥–∏—è –∞–Ω—Å–∞–º–±–ª—è
            weights (tuple): –í–µ—Å–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π (lstm_weight, autoencoder_weight)
        
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω—Å–∞–º–±–ª—è
        """
        print(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –º–æ–¥–µ–ª–µ–π...")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–∫–æ—Ä—ã –æ—Ç –æ–±–µ–∏—Ö –º–æ–¥–µ–ª–µ–π
        lstm_scores = self.get_lstm_scores(test_loader)
        autoencoder_scores = self.get_autoencoder_scores(test_loader)
        
        print(f"   üß† LSTM —Å–∫–æ—Ä—ã: {len(lstm_scores)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        print(f"   ü§ñ –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä —Å–∫–æ—Ä—ã: {len(autoencoder_scores)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ–≤ (0-1)
        lstm_scores_norm = (lstm_scores - lstm_scores.min()) / (lstm_scores.max() - lstm_scores.min())
        autoencoder_scores_norm = (autoencoder_scores - autoencoder_scores.min()) / (autoencoder_scores.max() - autoencoder_scores.min())
        
        test_labels_np = test_labels.numpy() if hasattr(test_labels, 'numpy') else test_labels
        
        results = {}
        
        if strategy == "simple_voting":
            # –ü—Ä–æ—Å—Ç–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ (—Å—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ)
            ensemble_scores = (lstm_scores_norm + autoencoder_scores_norm) / 2
            results['method'] = "Simple Voting (50-50)"
            
        elif strategy == "weighted_voting":
            # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ
            if weights is None:
                # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞: –±–æ–ª—å—à–µ –≤–µ—Å –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º F1
                # LSTM F1=78.83%, –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä F1=71.67%
                w_lstm = 0.6  # –ë–æ–ª—å—à–µ –≤–µ—Å LSTM (—Ç–æ—á–Ω–æ—Å—Ç—å)
                w_autoencoder = 0.4  # –ú–µ–Ω—å—à–µ –≤–µ—Å –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞
            else:
                w_lstm, w_autoencoder = weights
            
            ensemble_scores = w_lstm * lstm_scores_norm + w_autoencoder * autoencoder_scores_norm
            results['method'] = f"Weighted Voting ({w_lstm:.1f}-{w_autoencoder:.1f})"
            results['weights'] = (w_lstm, w_autoencoder)
            
        elif strategy == "max_voting":
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä (–±–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ)
            ensemble_scores = np.maximum(lstm_scores_norm, autoencoder_scores_norm)
            results['method'] = "Max Voting (–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π)"
            
        elif strategy == "precision_focused":
            # –§–æ–∫—É—Å –Ω–∞ precision: –±–æ–ª—å—à–µ –≤–µ—Å LSTM
            w_lstm, w_autoencoder = 0.8, 0.2
            ensemble_scores = w_lstm * lstm_scores_norm + w_autoencoder * autoencoder_scores_norm
            results['method'] = f"Precision Focused ({w_lstm:.1f}-{w_autoencoder:.1f})"
            
        elif strategy == "recall_focused":
            # –§–æ–∫—É—Å –Ω–∞ recall: –±–æ–ª—å—à–µ –≤–µ—Å –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞
            w_lstm, w_autoencoder = 0.3, 0.7
            ensemble_scores = w_lstm * lstm_scores_norm + w_autoencoder * autoencoder_scores_norm
            results['method'] = f"Recall Focused ({w_lstm:.1f}-{w_autoencoder:.1f})"
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy}")
        
        # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
        best_threshold, best_metrics = self._find_optimal_threshold(ensemble_scores, test_labels_np)
        
        # –î–µ–ª–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = (ensemble_scores > best_threshold).astype(int)
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(test_labels_np, predictions)
        precision = precision_score(test_labels_np, predictions, zero_division=0)
        recall = recall_score(test_labels_np, predictions, zero_division=0)
        f1 = f1_score(test_labels_np, predictions, zero_division=0)
        roc_auc = roc_auc_score(test_labels_np, ensemble_scores)
        
        results.update({
            'ensemble_scores': ensemble_scores,
            'predictions': predictions,
            'threshold': best_threshold,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'roc_auc': roc_auc,
            'lstm_scores': lstm_scores_norm,
            'autoencoder_scores': autoencoder_scores_norm,
            'test_labels': test_labels_np
        })
        
        return results
    
    def _find_optimal_threshold(self, scores, labels):
        """–ù–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏–∏ F1-score."""
        thresholds = np.linspace(scores.min(), scores.max(), 100)
        best_f1 = 0
        best_threshold = 0.5
        best_metrics = {}
        
        for threshold in thresholds:
            predictions = (scores > threshold).astype(int)
            f1 = f1_score(labels, predictions, zero_division=0)
            
            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold
                best_metrics = {
                    'accuracy': accuracy_score(labels, predictions),
                    'precision': precision_score(labels, predictions, zero_division=0),
                    'recall': recall_score(labels, predictions, zero_division=0),
                    'f1_score': f1
                }
        
        return best_threshold, best_metrics

def test_all_ensemble_strategies():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∞–Ω—Å–∞–º–±–ª—è –∏ –Ω–∞—Ö–æ–¥–∏—Ç –ª—É—á—à—É—é."""
    print("üéØ –°–û–ó–î–ê–ù–ò–ï –ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ê–ù–°–ê–ú–ë–õ–Ø LSTM + –ê–í–¢–û–≠–ù–ö–û–î–ï–†")
    print("=" * 60)
    
    # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
    lstm_path = "trials/final_model/final_model_best.pth"
    autoencoder_path = "trials/autoencoder_vs_lstm_comparison/autoencoder_vs_lstm_comparison_best.pth"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π
    if not Path(lstm_path).exists():
        print(f"‚ùå LSTM –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {lstm_path}")
        return
    
    if not Path(autoencoder_path).exists():
        print(f"‚ùå –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω: {autoencoder_path}")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∞–Ω—Å–∞–º–±–ª—å
    ensemble = EnsembleModel(lstm_path, autoencoder_path)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    print(f"\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    _, _, (test_loader, test_labels) = get_data('plaid', batch_size=64)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    strategies = [
        ("simple_voting", "–ü—Ä–æ—Å—Ç–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ"),
        ("weighted_voting", "–í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ"),
        ("max_voting", "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ"),
        ("precision_focused", "–§–æ–∫—É—Å –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å"),
        ("recall_focused", "–§–æ–∫—É—Å –Ω–∞ –ø–æ–ª–Ω–æ—Ç—É")
    ]
    
    all_results = {}
    
    print(f"\nüî¨ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–¢–†–ê–¢–ï–ì–ò–ô –ê–ù–°–ê–ú–ë–õ–Ø:")
    print("-" * 60)
    
    for strategy, description in strategies:
        print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä—É—é: {description}")
        
        results = ensemble.predict_ensemble(test_loader, test_labels, strategy=strategy)
        all_results[strategy] = results
        
        print(f"   üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã {results['method']}:")
        print(f"      Accuracy:  {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)")
        print(f"      Precision: {results['precision']:.4f} ({results['precision']*100:.2f}%)")
        print(f"      Recall:    {results['recall']:.4f} ({results['recall']*100:.2f}%)")
        print(f"      F1-Score:  {results['f1_score']:.4f} ({results['f1_score']*100:.2f}%)")
        print(f"      ROC-AUC:   {results['roc_auc']:.4f} ({results['roc_auc']*100:.2f}%)")
        print(f"      –ü–æ—Ä–æ–≥:     {results['threshold']:.4f}")
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
    best_strategy = max(all_results.keys(), key=lambda k: all_results[k]['f1_score'])
    best_results = all_results[best_strategy]
    
    print(f"\nüèÜ –õ–£–ß–®–ê–Ø –°–¢–†–ê–¢–ï–ì–ò–Ø: {best_results['method']}")
    print("=" * 60)
    print(f"üéØ Accuracy:  {best_results['accuracy']*100:.2f}%")
    print(f"üéØ Precision: {best_results['precision']*100:.2f}%")
    print(f"üéØ Recall:    {best_results['recall']*100:.2f}%")
    print(f"üéØ F1-Score:  {best_results['f1_score']*100:.2f}%")
    print(f"üéØ ROC-AUC:   {best_results['roc_auc']*100:.2f}%")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –° –ò–°–•–û–î–ù–´–ú–ò –ú–û–î–ï–õ–Ø–ú–ò:")
    print("-" * 60)
    print(f"üß† LSTM:         94.30% Acc, 76.35% Prec, 81.48% Rec, 78.83% F1")
    print(f"ü§ñ –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä:  89.82% Acc, 56.24% Prec, 98.78% Rec, 71.67% F1")
    print(f"üéØ –ê–ù–°–ê–ú–ë–õ–¨:     {best_results['accuracy']*100:.2f}% Acc, {best_results['precision']*100:.2f}% Prec, {best_results['recall']*100:.2f}% Rec, {best_results['f1_score']*100:.2f}% F1")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–∏ 80%+
    goal_80_achieved = (
        best_results['accuracy'] >= 0.80 and
        best_results['precision'] >= 0.80 and
        best_results['recall'] >= 0.80 and
        best_results['f1_score'] >= 0.80
    )
    
    if goal_80_achieved:
        print(f"\nüéâ –¶–ï–õ–¨ –î–û–°–¢–ò–ì–ù–£–¢–ê! –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ ‚â• 80%!")
    else:
        print(f"\nüìà –ü—Ä–æ–≥—Ä–µ—Å—Å –∫ —Ü–µ–ª–∏ 80%:")
        metrics_80 = {
            'Accuracy': best_results['accuracy'] >= 0.80,
            'Precision': best_results['precision'] >= 0.80,
            'Recall': best_results['recall'] >= 0.80,
            'F1-Score': best_results['f1_score'] >= 0.80
        }
        for metric, achieved in metrics_80.items():
            status = "‚úÖ" if achieved else "‚ùå"
            print(f"   {status} {metric}: {best_results[metric.lower().replace('-', '_')]*100:.2f}%")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    output_dir = Path("trials/ensemble_results")
    output_dir.mkdir(exist_ok=True)
    
    with open(output_dir / "ensemble_results.pkl", 'wb') as f:
        pickle.dump(all_results, f)
    
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
    
    return all_results

if __name__ == "__main__":
    test_all_ensemble_strategies() 